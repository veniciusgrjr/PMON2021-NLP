{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter core     : 4.6.3\n",
      "jupyter-notebook : 6.1.4\n",
      "qtconsole        : 4.7.7\n",
      "ipython          : 7.19.0\n",
      "ipykernel        : 5.3.4\n",
      "jupyter client   : 6.1.7\n",
      "jupyter lab      : 2.2.6\n",
      "nbconvert        : 6.0.7\n",
      "ipywidgets       : 7.5.1\n",
      "nbformat         : 5.0.8\n",
      "traitlets        : 5.0.5\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from bert_serving.client import BertClient\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def vectorization_TF_IDF(DATASET, text_field_name, label_name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split( DATASET[text_field_name] ,\n",
    "                                                    DATASET[label_name], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_v = vectorizer.fit_transform(X_train.apply(str))\n",
    "    X_test_v = vectorizer.transform(X_test.apply(str))\n",
    "    \n",
    "    return X_train_v, X_test_v, y_train, y_test\n",
    "\n",
    "def saving_results(results, path, file_name):\n",
    "\n",
    "    results.to_csv(path + file_name,  index = False, sep=\";\")\n",
    "    \n",
    "def train_model(classifier, X_train_v, X_test_v, y_train, y_test):\n",
    "    ini = time.time()\n",
    "    classifier.fit(X_train_v, y_train)\n",
    "    predictions = classifier.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    \n",
    "    return fim-ini, metrics.accuracy_score(predictions, y_test), predictions\n",
    "\n",
    "def get_tests_result(X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    all_res = []\n",
    "    ### MLPClassifier\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, ), random_state=1, verbose=True)\n",
    "    train_test_time, accuracy, Y_Previsto_MLP = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"MLPClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"MLPClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### AdaBoostClassifier\n",
    "    clf = AdaBoostClassifier(n_estimators= 50, learning_rate=1)\n",
    "    train_test_time, accuracy, Y_Previsto_ada = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"AdaBoostClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"AdaBoostClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### Voting_LR3_SVC1_ETC2\n",
    "    ini = time.time()\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf5 = SVC(kernel='rbf', probability=True)\n",
    "    clf6 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    eclf = VotingClassifier(estimators=[ ('lr', clf2), ('svc', clf5), ('etc', clf6)], voting='soft', weights=[3, 1, 2])\n",
    "    clf2 = clf2.fit(X_train_v, y_train)\n",
    "    clf5 = clf5.fit(X_train_v, y_train)\n",
    "    clf6 = clf6.fit(X_train_v, y_train)\n",
    "    eclf = eclf.fit(X_train_v, y_train)\n",
    "    Y_previsto_vc1 = eclf.predict(X_test_v.toarray())\n",
    "    fim = time.time()\n",
    "    train_test_time = fim - ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_previsto_vc1)\n",
    "    #print( \"Voting_LR3_SVC1_ETC2: \" + str( accuracy) ) \n",
    "    all_res.append([\"Voting_LR3_SVC1_ETC2: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### Voting_LR1_SVC1_ETC1\n",
    "    ini = time.time()\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf5 = SVC(kernel='rbf', probability=True)\n",
    "    clf6 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    eclf = VotingClassifier(estimators=[ ('lr', clf2), ('svc', clf5), ('etc', clf6)], voting='soft', weights=[1, 1, 1])\n",
    "    clf2 = clf2.fit(X_train_v, y_train)\n",
    "    clf5 = clf5.fit(X_train_v, y_train)\n",
    "    clf6 = clf6.fit(X_train_v, y_train)\n",
    "    eclf = eclf.fit(X_train_v, y_train)\n",
    "    Y_previsto_vc2 = eclf.predict(X_test_v.toarray())\n",
    "    fim = time.time()\n",
    "    train_test_time = fim - ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_previsto_vc2)\n",
    "    #print( \"Voting_LR1_SVC1_ETC1: \" + str( accuracy) ) \n",
    "    all_res.append([\"Voting_LR1_SVC1_ETC1: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_DTC = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"DecisionTreeClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"DecisionTreeClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_G = train_model(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"GaussianNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"GaussianNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### BernoulliNB\n",
    "    clf = BernoulliNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_B = train_model(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"BernoulliNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"BernoulliNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### MultinomialNB\n",
    "    clf = MultinomialNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_M = train_model(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"MultinomialNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"MultinomialNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    train_test_time, accuracy, Y_previsto_RF = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"RandomForestClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"RandomForestClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### ExtraTreesClassifier\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_ERT = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"ExtraTreesClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"ExtraTreesClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_LR = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"LogisticRegression: \" + str( accuracy) ) \n",
    "    all_res.append([\"LogisticRegression: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm\n",
    "    clf = svm.SVC()\n",
    "    train_test_time, accuracy, Y_previsto_SVM = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm_rbf\n",
    "    clf = svm.SVC(kernel='rbf', probability=True)\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm_rbf: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm_rbf: \", train_test_time, accuracy])\n",
    "        \n",
    "    ### Stacking 1\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc1[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc2[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_1: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 2\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        #elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc1[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc2[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_2: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 3\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_vc1[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc2[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_3: \", 0 , accuracy]) \n",
    "    \n",
    "    ### Stacking_scikit\n",
    "    clf1 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf3 = SVC()\n",
    "    clf4 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    estimators = [('rf', clf1), ('lr', clf2), ('svc', clf3), ('etc', clf4)]\n",
    "    ini = time.time()\n",
    "    clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression(), n_jobs=None)\n",
    "    clf.fit(X_train_v, y_train)\n",
    "    Y_Previsto_stacking = clf.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_Previsto_stacking)\n",
    "    all_res.append([\"Stacking_scikit: \", train_test_time , accuracy])\n",
    "    \n",
    "    ### XGBClassifier\n",
    "    clf = XGBClassifier(eval_metric='mlogloss')\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model(clf, X_train_v.tocsc(), X_test_v.tocsc(), y_train, y_test)\n",
    "    #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### OneVsRestClassifier_RF\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    ovr = OneVsRestClassifier(clf)\n",
    "    ini = time.time()\n",
    "    ovr.fit(X_train_v, y_train)\n",
    "    Y_Previsto_OVR_RF = ovr.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(Y_Previsto_OVR_RF, y_test)\n",
    "    all_res.append([\"OvR_RF: \", train_test_time , accuracy])\n",
    "    \n",
    "    return pd.DataFrame( all_res, columns=[\"ALGORITHM\",\"TRAIN_TEST_TIME\", \"ACCURACY\"]  )\n",
    "\n",
    "def train_model_ovo(classifier, X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    ini = time.time()\n",
    "    ovo = OneVsOneClassifier(classifier)\n",
    "    ovo.fit(X_train_v, y_train)\n",
    "    predictions = ovo.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    \n",
    "    return fim-ini, metrics.accuracy_score(predictions, y_test), predictions\n",
    "\n",
    "def get_tests_result_ovo(X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    all_res = []\n",
    "    ### MLPClassifier\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, ), random_state=1, verbose=True)\n",
    "    train_test_time, accuracy, Y_Previsto_MLP = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"MLPClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"MLPClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### AdaBoostClassifier\n",
    "    clf = AdaBoostClassifier(n_estimators= 50, learning_rate=1)\n",
    "    train_test_time, accuracy, Y_Previsto_ada = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"AdaBoostClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"AdaBoostClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### Voting_LR3_SVC1_ETC2\n",
    "    all_res.append([\"Voting_LR3_SVC1_ETC2: \", 0 , 0 ])\n",
    "    \n",
    "    ### Voting_LR1_SVC1_ETC1\n",
    "    all_res.append([\"Voting_LR1_SVC1_ETC1: \", 0, 0])\n",
    "    \n",
    "    ### DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_DTC = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"DecisionTreeClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"DecisionTreeClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_G = train_model_ovo(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"GaussianNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"GaussianNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### BernoulliNB\n",
    "    clf = BernoulliNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_B = train_model_ovo(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"BernoulliNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"BernoulliNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### MultinomialNB\n",
    "    clf = MultinomialNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_M = train_model_ovo(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"MultinomialNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"MultinomialNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    train_test_time, accuracy, Y_previsto_RF = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"RandomForestClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"RandomForestClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### ExtraTreesClassifier\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_ERT = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"ExtraTreesClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"ExtraTreesClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_LR = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"LogisticRegression: \" + str( accuracy) ) \n",
    "    all_res.append([\"LogisticRegression: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm\n",
    "    clf = svm.SVC()\n",
    "    train_test_time, accuracy, Y_previsto_SVM = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm_rbf\n",
    "    clf = svm.SVC(kernel='rbf', probability=True)\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm_rbf: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm_rbf: \", train_test_time, accuracy])\n",
    "        \n",
    "    ### Stacking 1\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_1: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 2\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        #elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_2: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 3\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_3: \", 0 , accuracy]) \n",
    "    \n",
    "    ### Stacking_scikit\n",
    "    clf1 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf3 = SVC()\n",
    "    clf4 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    estimators = [('rf', clf1), ('lr', clf2), ('svc', clf3), ('etc', clf4)]\n",
    "    ini = time.time()\n",
    "    clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression(), n_jobs=None)\n",
    "    \n",
    "    ovo = OneVsOneClassifier(clf)\n",
    "    ovo.fit(X_train_v, y_train)\n",
    "    Y_Previsto_stacking = ovo.predict(X_test_v)\n",
    "    \n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_Previsto_stacking)\n",
    "    all_res.append([\"Stacking_scikit_ovo: \", train_test_time , accuracy])\n",
    "    \n",
    "    ### XGBClassifier\n",
    "    clf = XGBClassifier(eval_metric='mlogloss')\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model_ovo(clf, X_train_v.tocsc(), X_test_v.tocsc(), y_train, y_test)\n",
    "    #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    return pd.DataFrame( all_res, columns=[\"ALGORITHM\",\"TRAIN_TEST_TIME\", \"ACCURACY\"]  )\n",
    "    \n",
    "    \n",
    "def train_model_ovr(classifier, X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    ini = time.time()\n",
    "    ovr = OneVsRestClassifier(classifier)\n",
    "    try:\n",
    "        ovr.fit(X_train_v, y_train)\n",
    "    except:\n",
    "        ovr.fit(X_train_v.toarray(), y_train)\n",
    "    predictions = ovr.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    \n",
    "    return fim-ini, metrics.accuracy_score(predictions, y_test), predictions\n",
    "\n",
    "def get_tests_result_ovr(X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    all_res = []    \n",
    "    ### MLPClassifier\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, ), random_state=1, verbose=True)\n",
    "    train_test_time, accuracy, Y_Previsto_MLP = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"MLPClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"MLPClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### AdaBoostClassifier\n",
    "    clf = AdaBoostClassifier(n_estimators= 50, learning_rate=1)\n",
    "    train_test_time, accuracy, Y_Previsto_ada = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"AdaBoostClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"AdaBoostClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### Voting_LR3_SVC1_ETC2\n",
    "    all_res.append([\"Voting_LR3_SVC1_ETC2: \", 0 , 0 ])\n",
    "    \n",
    "    ### Voting_LR1_SVC1_ETC1\n",
    "    all_res.append([\"Voting_LR1_SVC1_ETC1: \", 0, 0])\n",
    "    \n",
    "    ### DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_DTC = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"DecisionTreeClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"DecisionTreeClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### GaussianNB\n",
    "    Y_previsto_NB_G = 1\n",
    "    try:\n",
    "        clf = GaussianNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_G = train_model_ovr(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "        #print( \"GaussianNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"GaussianNB: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = GaussianNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_G = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"GaussianNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"GaussianNB: \", train_test_time, accuracy])\n",
    "      \n",
    "    \n",
    "    ### BernoulliNB\n",
    "    Y_previsto_NB_B = 1\n",
    "    try:\n",
    "        clf = BernoulliNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_B = train_model_ovr(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "        #print( \"BernoulliNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"BernoulliNB: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = BernoulliNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_B = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"BernoulliNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"BernoulliNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### MultinomialNB\n",
    "    Y_previsto_NB_M = 1\n",
    "    try:\n",
    "        clf = MultinomialNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_M = train_model_ovr(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "        #print( \"MultinomialNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"MultinomialNB: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = MultinomialNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_M = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"MultinomialNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"MultinomialNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    train_test_time, accuracy, Y_previsto_RF = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"RandomForestClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"RandomForestClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### ExtraTreesClassifier\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_ERT = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"ExtraTreesClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"ExtraTreesClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_LR = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"LogisticRegression: \" + str( accuracy) ) \n",
    "    all_res.append([\"LogisticRegression: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm\n",
    "    clf = svm.SVC()\n",
    "    train_test_time, accuracy, Y_previsto_SVM = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm_rbf\n",
    "    clf = svm.SVC(kernel='rbf', probability=True)\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm_rbf: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm_rbf: \", train_test_time, accuracy])\n",
    "        \n",
    "    ### Stacking 1\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_1: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 2\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        #elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_2: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 3\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_3: \", 0 , accuracy]) \n",
    "    \n",
    "    ### Stacking_scikit\n",
    "    clf1 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf3 = SVC()\n",
    "    clf4 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    estimators = [('rf', clf1), ('lr', clf2), ('svc', clf3), ('etc', clf4)]\n",
    "    ini = time.time()\n",
    "    clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression(), n_jobs=None)\n",
    "    \n",
    "    ovr = OneVsRestClassifier(clf)\n",
    "    ovr.fit(X_train_v, y_train)\n",
    "    Y_Previsto_stacking = ovr.predict(X_test_v)\n",
    "    \n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_Previsto_stacking)\n",
    "    all_res.append([\"Stacking_scikit_ovr: \", train_test_time , accuracy])\n",
    "    \n",
    "    ### XGBClassifier\n",
    "    Y_previsto_xgbc = 1\n",
    "    try:\n",
    "        clf = XGBClassifier(eval_metric='mlogloss')\n",
    "        train_test_time, accuracy, Y_previsto_xgbc = train_model_ovr(clf, X_train_v.tocsc(), X_test_v.tocsc(), y_train, y_test)\n",
    "        #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "        all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = XGBClassifier(eval_metric='mlogloss')\n",
    "        train_test_time, accuracy, Y_previsto_xgbc = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "        all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    return pd.DataFrame( all_res, columns=[\"ALGORITHM\",\"TRAIN_TEST_TIME\", \"ACCURACY\"]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening exemple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RELATOCLIENTE</th>\n",
       "      <th>PROBLEMA</th>\n",
       "      <th>RELATOCLIENTE_CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cliente entrou em contato informando que está ...</td>\n",
       "      <td>Queda / Intermitência</td>\n",
       "      <td>cliente entrou contato informando esta sem sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLIENTE COM QUEDAS REALIZEI OS TESTE E ENCAMIN...</td>\n",
       "      <td>Queda / Intermitência</td>\n",
       "      <td>cliente com quedas realizei teste encaminhei s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cliente reclama de quedas e intermitência , pr...</td>\n",
       "      <td>Queda / Intermitência</td>\n",
       "      <td>cliente reclama quedas intermitencia procedime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLIENTE INFORMA QUE INTERNET ESTA COM QUEDAS H...</td>\n",
       "      <td>Queda / Intermitência</td>\n",
       "      <td>cliente informa internet esta com quedas mais ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       RELATOCLIENTE               PROBLEMA  \\\n",
       "0  cliente entrou em contato informando que está ...  Queda / Intermitência   \n",
       "1  CLIENTE COM QUEDAS REALIZEI OS TESTE E ENCAMIN...  Queda / Intermitência   \n",
       "2  Cliente reclama de quedas e intermitência , pr...  Queda / Intermitência   \n",
       "3  CLIENTE INFORMA QUE INTERNET ESTA COM QUEDAS H...  Queda / Intermitência   \n",
       "\n",
       "                                 RELATOCLIENTE_CLEAN  \n",
       "0  cliente entrou contato informando esta sem sin...  \n",
       "1  cliente com quedas realizei teste encaminhei s...  \n",
       "2  cliente reclama quedas intermitencia procedime...  \n",
       "3  cliente informa internet esta com quedas mais ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "DATASET.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 0 with the exemple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.234905</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.078104</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.374932</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.374116</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.062485</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.124585</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.015650</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.343421</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.249921</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.234905  0.616667\n",
       "1       AdaBoostClassifier:          0.078104  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.374932  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.374116  0.650000\n",
       "4   DecisionTreeClassifier:          0.015619  0.583333\n",
       "5               GaussianNB:          0.000000  0.500000\n",
       "6              BernoulliNB:          0.000000  0.616667\n",
       "7            MultinomialNB:          0.000000  0.633333\n",
       "8   RandomForestClassifier:          0.062485  0.666667\n",
       "9     ExtraTreesClassifier:          0.124585  0.633333\n",
       "10      LogisticRegression:          0.015650  0.700000\n",
       "11                     svm:          0.015620  0.633333\n",
       "12                 svm_rbf:          0.062488  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.343421  0.616667\n",
       "17           XGBClassifier:          0.249921  0.683333\n",
       "18                  OvR_RF:          0.359318  0.633333"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 with the complete dataset\n",
    "* Todas as palavras da base;\n",
    "* Removendo apenas stopwords;\n",
    "* 3000 registros para cada classe de problema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>22.525683</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>1.187195</td>\n",
       "      <td>0.729444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>232.752228</td>\n",
       "      <td>0.845833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>229.672287</td>\n",
       "      <td>0.844722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>1.187206</td>\n",
       "      <td>0.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>4.311490</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>1.765204</td>\n",
       "      <td>0.755278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.687306</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>9.506714</td>\n",
       "      <td>0.833056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>27.601219</td>\n",
       "      <td>0.837222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.421509</td>\n",
       "      <td>0.817500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>18.986020</td>\n",
       "      <td>0.831944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>86.678408</td>\n",
       "      <td>0.831944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>376.997996</td>\n",
       "      <td>0.844722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>5.973329</td>\n",
       "      <td>0.832222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>24.876392</td>\n",
       "      <td>0.838611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         22.525683  0.807500\n",
       "1       AdaBoostClassifier:          1.187195  0.729444\n",
       "2     Voting_LR3_SVC1_ETC2:        232.752228  0.845833\n",
       "3     Voting_LR1_SVC1_ETC1:        229.672287  0.844722\n",
       "4   DecisionTreeClassifier:          1.187206  0.792500\n",
       "5               GaussianNB:          4.311490  0.522222\n",
       "6              BernoulliNB:          1.765204  0.755278\n",
       "7            MultinomialNB:          0.687306  0.766667\n",
       "8   RandomForestClassifier:          9.506714  0.833056\n",
       "9     ExtraTreesClassifier:         27.601219  0.837222\n",
       "10      LogisticRegression:          1.421509  0.817500\n",
       "11                     svm:         18.986020  0.831944\n",
       "12                 svm_rbf:         86.678408  0.831944\n",
       "13              stacking_1:          0.000000  0.843333\n",
       "14              stacking_2:          0.000000  0.845278\n",
       "15              stacking_3:          0.000000  0.842778\n",
       "16         Stacking_scikit:        376.997996  0.844722\n",
       "17           XGBClassifier:          5.973329  0.832222\n",
       "18                  OvR_RF:         24.876392  0.838611"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 with the complete dataset\n",
    "* Todas as palavras da base;\n",
    "* Removendo apenas stopwords;\n",
    "* 7000 registros para cada classe de problema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>44.014814</td>\n",
       "      <td>0.820476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>2.796191</td>\n",
       "      <td>0.728095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>1023.333115</td>\n",
       "      <td>0.846190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>1021.191428</td>\n",
       "      <td>0.847857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>4.787648</td>\n",
       "      <td>0.803095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>48.597214</td>\n",
       "      <td>0.489167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>9.263345</td>\n",
       "      <td>0.764881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>2.827443</td>\n",
       "      <td>0.774524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>37.561203</td>\n",
       "      <td>0.841071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>109.020018</td>\n",
       "      <td>0.840595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>2.952439</td>\n",
       "      <td>0.825595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>89.642022</td>\n",
       "      <td>0.841548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>404.954998</td>\n",
       "      <td>0.841548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1504.947471</td>\n",
       "      <td>0.848214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>14.452220</td>\n",
       "      <td>0.839048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>95.640793</td>\n",
       "      <td>0.841429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         44.014814  0.820476\n",
       "1       AdaBoostClassifier:          2.796191  0.728095\n",
       "2     Voting_LR3_SVC1_ETC2:       1023.333115  0.846190\n",
       "3     Voting_LR1_SVC1_ETC1:       1021.191428  0.847857\n",
       "4   DecisionTreeClassifier:          4.787648  0.803095\n",
       "5               GaussianNB:         48.597214  0.489167\n",
       "6              BernoulliNB:          9.263345  0.764881\n",
       "7            MultinomialNB:          2.827443  0.774524\n",
       "8   RandomForestClassifier:         37.561203  0.841071\n",
       "9     ExtraTreesClassifier:        109.020018  0.840595\n",
       "10      LogisticRegression:          2.952439  0.825595\n",
       "11                     svm:         89.642022  0.841548\n",
       "12                 svm_rbf:        404.954998  0.841548\n",
       "13              stacking_1:          0.000000  0.847857\n",
       "14              stacking_2:          0.000000  0.848214\n",
       "15              stacking_3:          0.000000  0.850952\n",
       "16         Stacking_scikit:       1504.947471  0.848214\n",
       "17           XGBClassifier:         14.452220  0.839048\n",
       "18                  OvR_RF:         95.640793  0.841429"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 with the complete dataset\n",
    "* Removendo as 6 palavras mais frequentes da base;\n",
    "* Removendo stopwords;\n",
    "* 3000 registros para cada classe de problema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>21.032017</td>\n",
       "      <td>0.760278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>0.628611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>217.203632</td>\n",
       "      <td>0.792222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>217.516733</td>\n",
       "      <td>0.789722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>1.124703</td>\n",
       "      <td>0.735833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>4.022254</td>\n",
       "      <td>0.511667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>1.702696</td>\n",
       "      <td>0.697778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.671700</td>\n",
       "      <td>0.711944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>9.653968</td>\n",
       "      <td>0.779167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>28.250865</td>\n",
       "      <td>0.778333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.350897</td>\n",
       "      <td>0.769444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>17.464517</td>\n",
       "      <td>0.782778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>80.230633</td>\n",
       "      <td>0.782778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>395.890710</td>\n",
       "      <td>0.793333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>5.167006</td>\n",
       "      <td>0.778611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>26.009489</td>\n",
       "      <td>0.785000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         21.032017  0.760278\n",
       "1       AdaBoostClassifier:          0.968526  0.628611\n",
       "2     Voting_LR3_SVC1_ETC2:        217.203632  0.792222\n",
       "3     Voting_LR1_SVC1_ETC1:        217.516733  0.789722\n",
       "4   DecisionTreeClassifier:          1.124703  0.735833\n",
       "5               GaussianNB:          4.022254  0.511667\n",
       "6              BernoulliNB:          1.702696  0.697778\n",
       "7            MultinomialNB:          0.671700  0.711944\n",
       "8   RandomForestClassifier:          9.653968  0.779167\n",
       "9     ExtraTreesClassifier:         28.250865  0.778333\n",
       "10      LogisticRegression:          1.350897  0.769444\n",
       "11                     svm:         17.464517  0.782778\n",
       "12                 svm_rbf:         80.230633  0.782778\n",
       "13              stacking_1:          0.000000  0.789167\n",
       "14              stacking_2:          0.000000  0.791944\n",
       "15              stacking_3:          0.000000  0.790278\n",
       "16         Stacking_scikit:        395.890710  0.793333\n",
       "17           XGBClassifier:          5.167006  0.778611\n",
       "18                  OvR_RF:         26.009489  0.785000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4 with the complete dataset\n",
    "* Base composta pelas 700 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 3000 registros para cada classe de problema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>7.648513</td>\n",
       "      <td>0.802500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.906034</td>\n",
       "      <td>0.714722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>133.119194</td>\n",
       "      <td>0.826111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>133.209067</td>\n",
       "      <td>0.826389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.718576</td>\n",
       "      <td>0.769167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.343667</td>\n",
       "      <td>0.615833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.140561</td>\n",
       "      <td>0.750556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.046831</td>\n",
       "      <td>0.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>4.545769</td>\n",
       "      <td>0.818333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>11.325487</td>\n",
       "      <td>0.821111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.562355</td>\n",
       "      <td>0.798889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>12.317178</td>\n",
       "      <td>0.815278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>55.798783</td>\n",
       "      <td>0.815278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.824444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.827500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>147.999595</td>\n",
       "      <td>0.827500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>4.896884</td>\n",
       "      <td>0.820833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>14.194495</td>\n",
       "      <td>0.818611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          7.648513  0.802500\n",
       "1       AdaBoostClassifier:          0.906034  0.714722\n",
       "2     Voting_LR3_SVC1_ETC2:        133.119194  0.826111\n",
       "3     Voting_LR1_SVC1_ETC1:        133.209067  0.826389\n",
       "4   DecisionTreeClassifier:          0.718576  0.769167\n",
       "5               GaussianNB:          0.343667  0.615833\n",
       "6              BernoulliNB:          0.140561  0.750556\n",
       "7            MultinomialNB:          0.046831  0.747500\n",
       "8   RandomForestClassifier:          4.545769  0.818333\n",
       "9     ExtraTreesClassifier:         11.325487  0.821111\n",
       "10      LogisticRegression:          0.562355  0.798889\n",
       "11                     svm:         12.317178  0.815278\n",
       "12                 svm_rbf:         55.798783  0.815278\n",
       "13              stacking_1:          0.000000  0.824444\n",
       "14              stacking_2:          0.000000  0.825278\n",
       "15              stacking_3:          0.000000  0.827500\n",
       "16         Stacking_scikit:        147.999595  0.827500\n",
       "17           XGBClassifier:          4.896884  0.820833\n",
       "18                  OvR_RF:         14.194495  0.818611"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5 with the complete dataset\n",
    "* Base composta pelas 700 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 7000 registros para cada classe de problema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>16.311365</td>\n",
       "      <td>0.809167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>2.253941</td>\n",
       "      <td>0.736905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>567.599483</td>\n",
       "      <td>0.835833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>569.039031</td>\n",
       "      <td>0.839286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>2.874319</td>\n",
       "      <td>0.792976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>1.187207</td>\n",
       "      <td>0.551429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.531105</td>\n",
       "      <td>0.752976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.140596</td>\n",
       "      <td>0.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>16.049357</td>\n",
       "      <td>0.831310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>42.435655</td>\n",
       "      <td>0.833810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.421544</td>\n",
       "      <td>0.806786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>55.251961</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>246.844422</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>572.774021</td>\n",
       "      <td>0.839881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>11.299681</td>\n",
       "      <td>0.827738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>47.199398</td>\n",
       "      <td>0.832976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         16.311365  0.809167\n",
       "1       AdaBoostClassifier:          2.253941  0.736905\n",
       "2     Voting_LR3_SVC1_ETC2:        567.599483  0.835833\n",
       "3     Voting_LR1_SVC1_ETC1:        569.039031  0.839286\n",
       "4   DecisionTreeClassifier:          2.874319  0.792976\n",
       "5               GaussianNB:          1.187207  0.551429\n",
       "6              BernoulliNB:          0.531105  0.752976\n",
       "7            MultinomialNB:          0.140596  0.755000\n",
       "8   RandomForestClassifier:         16.049357  0.831310\n",
       "9     ExtraTreesClassifier:         42.435655  0.833810\n",
       "10      LogisticRegression:          1.421544  0.806786\n",
       "11                     svm:         55.251961  0.833333\n",
       "12                 svm_rbf:        246.844422  0.833333\n",
       "13              stacking_1:          0.000000  0.836786\n",
       "14              stacking_2:          0.000000  0.838571\n",
       "15              stacking_3:          0.000000  0.838095\n",
       "16         Stacking_scikit:        572.774021  0.839881\n",
       "17           XGBClassifier:         11.299681  0.827738\n",
       "18                  OvR_RF:         47.199398  0.832976"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 6 with the complete dataset\n",
    "* Base composta pelas 4000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 3000 registros para cada classe de problema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>10.767277</td>\n",
       "      <td>0.797778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>1.031028</td>\n",
       "      <td>0.719444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>180.855142</td>\n",
       "      <td>0.831944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>180.751031</td>\n",
       "      <td>0.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.921629</td>\n",
       "      <td>0.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>1.218483</td>\n",
       "      <td>0.579722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.437374</td>\n",
       "      <td>0.754722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.187454</td>\n",
       "      <td>0.761944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>5.936090</td>\n",
       "      <td>0.822778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>15.566128</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.874817</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>16.527357</td>\n",
       "      <td>0.828056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>75.379857</td>\n",
       "      <td>0.828056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>203.551279</td>\n",
       "      <td>0.836389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>5.514289</td>\n",
       "      <td>0.827778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>16.839776</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         10.767277  0.797778\n",
       "1       AdaBoostClassifier:          1.031028  0.719444\n",
       "2     Voting_LR3_SVC1_ETC2:        180.855142  0.831944\n",
       "3     Voting_LR1_SVC1_ETC1:        180.751031  0.832500\n",
       "4   DecisionTreeClassifier:          0.921629  0.777500\n",
       "5               GaussianNB:          1.218483  0.579722\n",
       "6              BernoulliNB:          0.437374  0.754722\n",
       "7            MultinomialNB:          0.187454  0.761944\n",
       "8   RandomForestClassifier:          5.936090  0.822778\n",
       "9     ExtraTreesClassifier:         15.566128  0.826667\n",
       "10      LogisticRegression:          0.874817  0.816667\n",
       "11                     svm:         16.527357  0.828056\n",
       "12                 svm_rbf:         75.379857  0.828056\n",
       "13              stacking_1:          0.000000  0.835278\n",
       "14              stacking_2:          0.000000  0.833056\n",
       "15              stacking_3:          0.000000  0.835278\n",
       "16         Stacking_scikit:        203.551279  0.836389\n",
       "17           XGBClassifier:          5.514289  0.827778\n",
       "18                  OvR_RF:         16.839776  0.826667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 7 with the complete dataset\n",
    "* Base composta pelas 4000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 7000 registros para cada classe de problema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>20.798002</td>\n",
       "      <td>0.824881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>2.530650</td>\n",
       "      <td>0.735119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>775.397416</td>\n",
       "      <td>0.847024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>774.824264</td>\n",
       "      <td>0.848929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>3.811598</td>\n",
       "      <td>0.797738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>3.296098</td>\n",
       "      <td>0.590714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>1.218468</td>\n",
       "      <td>0.764881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.499856</td>\n",
       "      <td>0.770714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>20.413749</td>\n",
       "      <td>0.838214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>53.216350</td>\n",
       "      <td>0.842143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.866307</td>\n",
       "      <td>0.822976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>75.270957</td>\n",
       "      <td>0.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>339.900697</td>\n",
       "      <td>0.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>746.058939</td>\n",
       "      <td>0.848571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>13.199975</td>\n",
       "      <td>0.835357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>56.938915</td>\n",
       "      <td>0.839048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         20.798002  0.824881\n",
       "1       AdaBoostClassifier:          2.530650  0.735119\n",
       "2     Voting_LR3_SVC1_ETC2:        775.397416  0.847024\n",
       "3     Voting_LR1_SVC1_ETC1:        774.824264  0.848929\n",
       "4   DecisionTreeClassifier:          3.811598  0.797738\n",
       "5               GaussianNB:          3.296098  0.590714\n",
       "6              BernoulliNB:          1.218468  0.764881\n",
       "7            MultinomialNB:          0.499856  0.770714\n",
       "8   RandomForestClassifier:         20.413749  0.838214\n",
       "9     ExtraTreesClassifier:         53.216350  0.842143\n",
       "10      LogisticRegression:          1.866307  0.822976\n",
       "11                     svm:         75.270957  0.841667\n",
       "12                 svm_rbf:        339.900697  0.841667\n",
       "13              stacking_1:          0.000000  0.849048\n",
       "14              stacking_2:          0.000000  0.849167\n",
       "15              stacking_3:          0.000000  0.849048\n",
       "16         Stacking_scikit:        746.058939  0.848571\n",
       "17           XGBClassifier:         13.199975  0.835357\n",
       "18                  OvR_RF:         56.938915  0.839048"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 8 with the complete dataset\n",
    "* Todas as palavras da base;\n",
    "* Removendo stopwords;\n",
    "* BERT as service para português;\n",
    "* 3000 registros para cada classe de problema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train, X_test, y_train, y_test = train_test_split( DATASET[\"RELATOCLIENTE_CLEAN\"] ,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.8, random_state=42)\n",
    "\n",
    "bc = BertClient()\n",
    "X_train_bert = bc.encode(X_train.tolist())\n",
    "X_test_bert = bc.encode(X_test.tolist())\n",
    "X_train_v = X_train_bert.copy()\n",
    "X_test_v = X_test_bert.copy()\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 9 with the complete dataset\n",
    "* Base composta pelas 5000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>21.357614</td>\n",
       "      <td>0.841608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>2.614887</td>\n",
       "      <td>0.748437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>827.047537</td>\n",
       "      <td>0.868824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>851.638438</td>\n",
       "      <td>0.871644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>3.955573</td>\n",
       "      <td>0.823710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>4.040643</td>\n",
       "      <td>0.611867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>1.586694</td>\n",
       "      <td>0.785093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.581613</td>\n",
       "      <td>0.797352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>21.848946</td>\n",
       "      <td>0.862082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>57.878238</td>\n",
       "      <td>0.866740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.868515</td>\n",
       "      <td>0.844673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>81.580152</td>\n",
       "      <td>0.866005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>363.958589</td>\n",
       "      <td>0.866005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.870541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.872012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>813.229347</td>\n",
       "      <td>0.871399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>13.898820</td>\n",
       "      <td>0.864411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>60.068403</td>\n",
       "      <td>0.866618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         21.357614  0.841608\n",
       "1       AdaBoostClassifier:          2.614887  0.748437\n",
       "2     Voting_LR3_SVC1_ETC2:        827.047537  0.868824\n",
       "3     Voting_LR1_SVC1_ETC1:        851.638438  0.871644\n",
       "4   DecisionTreeClassifier:          3.955573  0.823710\n",
       "5               GaussianNB:          4.040643  0.611867\n",
       "6              BernoulliNB:          1.586694  0.785093\n",
       "7            MultinomialNB:          0.581613  0.797352\n",
       "8   RandomForestClassifier:         21.848946  0.862082\n",
       "9     ExtraTreesClassifier:         57.878238  0.866740\n",
       "10      LogisticRegression:          1.868515  0.844673\n",
       "11                     svm:         81.580152  0.866005\n",
       "12                 svm_rbf:        363.958589  0.866005\n",
       "13              stacking_1:          0.000000  0.869560\n",
       "14              stacking_2:          0.000000  0.870541\n",
       "15              stacking_3:          0.000000  0.872012\n",
       "16         Stacking_scikit:        813.229347  0.871399\n",
       "17           XGBClassifier:         13.898820  0.864411\n",
       "18                  OvR_RF:         60.068403  0.866618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 with the complete dataset\n",
    "* Base composta pelas 10.000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>25.286812</td>\n",
       "      <td>0.847125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>2.717698</td>\n",
       "      <td>0.752973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>895.120084</td>\n",
       "      <td>0.873973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>852.675155</td>\n",
       "      <td>0.877283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>4.014678</td>\n",
       "      <td>0.828736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>6.021779</td>\n",
       "      <td>0.584038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>2.452552</td>\n",
       "      <td>0.787912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.874766</td>\n",
       "      <td>0.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>23.470762</td>\n",
       "      <td>0.870541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>64.249990</td>\n",
       "      <td>0.871889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.978366</td>\n",
       "      <td>0.848596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>79.954868</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>360.598797</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>896.482835</td>\n",
       "      <td>0.877774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>13.691743</td>\n",
       "      <td>0.863430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>63.390794</td>\n",
       "      <td>0.872380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         25.286812  0.847125\n",
       "1       AdaBoostClassifier:          2.717698  0.752973\n",
       "2     Voting_LR3_SVC1_ETC2:        895.120084  0.873973\n",
       "3     Voting_LR1_SVC1_ETC1:        852.675155  0.877283\n",
       "4   DecisionTreeClassifier:          4.014678  0.828736\n",
       "5               GaussianNB:          6.021779  0.584038\n",
       "6              BernoulliNB:          2.452552  0.787912\n",
       "7            MultinomialNB:          0.874766  0.800049\n",
       "8   RandomForestClassifier:         23.470762  0.870541\n",
       "9     ExtraTreesClassifier:         64.249990  0.871889\n",
       "10      LogisticRegression:          1.978366  0.848596\n",
       "11                     svm:         79.954868  0.872134\n",
       "12                 svm_rbf:        360.598797  0.872134\n",
       "13              stacking_1:          0.000000  0.876180\n",
       "14              stacking_2:          0.000000  0.876548\n",
       "15              stacking_3:          0.000000  0.877896\n",
       "16         Stacking_scikit:        896.482835  0.877774\n",
       "17           XGBClassifier:         13.691743  0.863430\n",
       "18                  OvR_RF:         63.390794  0.872380"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 11 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: TF-IDF;\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>43.982335</td>\n",
       "      <td>0.820476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>2.780555</td>\n",
       "      <td>0.728095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>1019.636085</td>\n",
       "      <td>0.846310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>1020.984297</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>4.826985</td>\n",
       "      <td>0.803095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>18.308182</td>\n",
       "      <td>0.489167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>9.130423</td>\n",
       "      <td>0.764881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>2.889920</td>\n",
       "      <td>0.774524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>37.389365</td>\n",
       "      <td>0.841071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>108.988802</td>\n",
       "      <td>0.840595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>2.968048</td>\n",
       "      <td>0.825595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>89.814008</td>\n",
       "      <td>0.841548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>404.590893</td>\n",
       "      <td>0.841548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1517.495696</td>\n",
       "      <td>0.848214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>14.503118</td>\n",
       "      <td>0.839048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>96.026573</td>\n",
       "      <td>0.841429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         43.982335  0.820476\n",
       "1       AdaBoostClassifier:          2.780555  0.728095\n",
       "2     Voting_LR3_SVC1_ETC2:       1019.636085  0.846310\n",
       "3     Voting_LR1_SVC1_ETC1:       1020.984297  0.847619\n",
       "4   DecisionTreeClassifier:          4.826985  0.803095\n",
       "5               GaussianNB:         18.308182  0.489167\n",
       "6              BernoulliNB:          9.130423  0.764881\n",
       "7            MultinomialNB:          2.889920  0.774524\n",
       "8   RandomForestClassifier:         37.389365  0.841071\n",
       "9     ExtraTreesClassifier:        108.988802  0.840595\n",
       "10      LogisticRegression:          2.968048  0.825595\n",
       "11                     svm:         89.814008  0.841548\n",
       "12                 svm_rbf:        404.590893  0.841548\n",
       "13              stacking_1:          0.000000  0.847976\n",
       "14              stacking_2:          0.000000  0.848214\n",
       "15              stacking_3:          0.000000  0.850952\n",
       "16         Stacking_scikit:       1517.495696  0.848214\n",
       "17           XGBClassifier:         14.503118  0.839048\n",
       "18                  OvR_RF:         96.026573  0.841429"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 12 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: CountVectorizer;\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>44.799707</td>\n",
       "      <td>0.854113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>1.568557</td>\n",
       "      <td>0.741326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>979.443391</td>\n",
       "      <td>0.871767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>979.797481</td>\n",
       "      <td>0.873360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>3.844656</td>\n",
       "      <td>0.831678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>17.186179</td>\n",
       "      <td>0.457153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>44.483205</td>\n",
       "      <td>0.781660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>40.640288</td>\n",
       "      <td>0.779331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>43.309963</td>\n",
       "      <td>0.874954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>112.096646</td>\n",
       "      <td>0.875690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>2.714070</td>\n",
       "      <td>0.847983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>99.300720</td>\n",
       "      <td>0.856197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>420.985994</td>\n",
       "      <td>0.856197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.874464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1423.056591</td>\n",
       "      <td>0.881452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>4.922069</td>\n",
       "      <td>0.863553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>107.629534</td>\n",
       "      <td>0.878509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         44.799707  0.854113\n",
       "1       AdaBoostClassifier:          1.568557  0.741326\n",
       "2     Voting_LR3_SVC1_ETC2:        979.443391  0.871767\n",
       "3     Voting_LR1_SVC1_ETC1:        979.797481  0.873360\n",
       "4   DecisionTreeClassifier:          3.844656  0.831678\n",
       "5               GaussianNB:         17.186179  0.457153\n",
       "6              BernoulliNB:         44.483205  0.781660\n",
       "7            MultinomialNB:         40.640288  0.779331\n",
       "8   RandomForestClassifier:         43.309963  0.874954\n",
       "9     ExtraTreesClassifier:        112.096646  0.875690\n",
       "10      LogisticRegression:          2.714070  0.847983\n",
       "11                     svm:         99.300720  0.856197\n",
       "12                 svm_rbf:        420.985994  0.856197\n",
       "13              stacking_1:          0.000000  0.874464\n",
       "14              stacking_2:          0.000000  0.873605\n",
       "15              stacking_3:          0.000000  0.881084\n",
       "16         Stacking_scikit:       1423.056591  0.881452\n",
       "17           XGBClassifier:          4.922069  0.863553\n",
       "18                  OvR_RF:        107.629534  0.878509"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "list_corpus = DATASET[\"RELATOCLIENTE_CLEAN2\"].tolist()\n",
    "list_labels = DATASET[\"PROBLEMA_N\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, train_size=0.80, \n",
    "                                                                                random_state=28)\n",
    "X_train_v, count_vectorizer = cv(X_train)\n",
    "X_test_v = count_vectorizer.transform(X_test)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 13 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: CountVectorizer;\n",
    "* Stemmed_RSLP ( radicais das palavras)\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>44.671921</td>\n",
       "      <td>0.854113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>1.568852</td>\n",
       "      <td>0.741326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>980.240971</td>\n",
       "      <td>0.871644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>977.951930</td>\n",
       "      <td>0.873360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>3.857208</td>\n",
       "      <td>0.831678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>17.012320</td>\n",
       "      <td>0.457153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>44.407019</td>\n",
       "      <td>0.781660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>40.612171</td>\n",
       "      <td>0.779331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>43.229818</td>\n",
       "      <td>0.874954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>112.225228</td>\n",
       "      <td>0.875690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>2.713523</td>\n",
       "      <td>0.847983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>86.883756</td>\n",
       "      <td>0.856197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>380.938797</td>\n",
       "      <td>0.856197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.874464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1418.727798</td>\n",
       "      <td>0.881452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>4.907119</td>\n",
       "      <td>0.863553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>107.457713</td>\n",
       "      <td>0.878509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         44.671921  0.854113\n",
       "1       AdaBoostClassifier:          1.568852  0.741326\n",
       "2     Voting_LR3_SVC1_ETC2:        980.240971  0.871644\n",
       "3     Voting_LR1_SVC1_ETC1:        977.951930  0.873360\n",
       "4   DecisionTreeClassifier:          3.857208  0.831678\n",
       "5               GaussianNB:         17.012320  0.457153\n",
       "6              BernoulliNB:         44.407019  0.781660\n",
       "7            MultinomialNB:         40.612171  0.779331\n",
       "8   RandomForestClassifier:         43.229818  0.874954\n",
       "9     ExtraTreesClassifier:        112.225228  0.875690\n",
       "10      LogisticRegression:          2.713523  0.847983\n",
       "11                     svm:         86.883756  0.856197\n",
       "12                 svm_rbf:        380.938797  0.856197\n",
       "13              stacking_1:          0.000000  0.874464\n",
       "14              stacking_2:          0.000000  0.873605\n",
       "15              stacking_3:          0.000000  0.881084\n",
       "16         Stacking_scikit:       1418.727798  0.881452\n",
       "17           XGBClassifier:          4.907119  0.863553\n",
       "18                  OvR_RF:        107.457713  0.878509"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "list_corpus = DATASET[\"RELATOCLIENTE_CLEAN\"].tolist()\n",
    "list_labels = DATASET[\"PROBLEMA\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, train_size=0.80, \n",
    "                                                                                random_state=28)\n",
    "X_train_v, count_vectorizer = cv(X_train)\n",
    "X_test_v = count_vectorizer.transform(X_test)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 14 with the complete dataset\n",
    "* Base composta pelas 10.000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: TF-IDF\n",
    "* Abordagem One vs One\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>161.366183</td>\n",
       "      <td>0.841486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>35.083257</td>\n",
       "      <td>0.817580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>9.281981</td>\n",
       "      <td>0.832904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>47.473135</td>\n",
       "      <td>0.589310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>25.576598</td>\n",
       "      <td>0.787912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>8.850272</td>\n",
       "      <td>0.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>60.533612</td>\n",
       "      <td>0.870173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>230.284074</td>\n",
       "      <td>0.870050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.034424</td>\n",
       "      <td>0.844918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>151.562483</td>\n",
       "      <td>0.871399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>427.984922</td>\n",
       "      <td>0.871399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.867231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovo:</td>\n",
       "      <td>1786.213848</td>\n",
       "      <td>0.875812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>12.637643</td>\n",
       "      <td>0.865759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:        161.366183  0.841486\n",
       "1       AdaBoostClassifier:         35.083257  0.817580\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          9.281981  0.832904\n",
       "5               GaussianNB:         47.473135  0.589310\n",
       "6              BernoulliNB:         25.576598  0.787912\n",
       "7            MultinomialNB:          8.850272  0.800049\n",
       "8   RandomForestClassifier:         60.533612  0.870173\n",
       "9     ExtraTreesClassifier:        230.284074  0.870050\n",
       "10      LogisticRegression:          1.034424  0.844918\n",
       "11                     svm:        151.562483  0.871399\n",
       "12                 svm_rbf:        427.984922  0.871399\n",
       "13              stacking_1:          0.000000  0.873728\n",
       "14              stacking_2:          0.000000  0.867231\n",
       "15              stacking_3:          0.000000  0.876670\n",
       "16     Stacking_scikit_ovo:       1786.213848  0.875812\n",
       "17           XGBClassifier:         12.637643  0.865759"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "\n",
    "results = get_tests_result_ovo(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 15 with the complete dataset\n",
    "* Base composta pelas 10.000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: TF-IDF\n",
    "* Abordagem One vs Rest\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>128.284923</td>\n",
       "      <td>0.853868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>14.277206</td>\n",
       "      <td>0.799068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>34.466916</td>\n",
       "      <td>0.802869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>24.768145</td>\n",
       "      <td>0.377835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>13.213651</td>\n",
       "      <td>0.796371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>3.695135</td>\n",
       "      <td>0.800172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>64.141342</td>\n",
       "      <td>0.872380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>196.135370</td>\n",
       "      <td>0.873238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.593136</td>\n",
       "      <td>0.842957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>545.421504</td>\n",
       "      <td>0.870295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>2235.310908</td>\n",
       "      <td>0.870295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.870295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>4198.317662</td>\n",
       "      <td>0.876057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>15.229001</td>\n",
       "      <td>0.862817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:        128.284923  0.853868\n",
       "1       AdaBoostClassifier:         14.277206  0.799068\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:         34.466916  0.802869\n",
       "5               GaussianNB:         24.768145  0.377835\n",
       "6              BernoulliNB:         13.213651  0.796371\n",
       "7            MultinomialNB:          3.695135  0.800172\n",
       "8   RandomForestClassifier:         64.141342  0.872380\n",
       "9     ExtraTreesClassifier:        196.135370  0.873238\n",
       "10      LogisticRegression:          1.593136  0.842957\n",
       "11                     svm:        545.421504  0.870295\n",
       "12                 svm_rbf:       2235.310908  0.870295\n",
       "13              stacking_1:          0.000000  0.873115\n",
       "14              stacking_2:          0.000000  0.870295\n",
       "15              stacking_3:          0.000000  0.877896\n",
       "16     Stacking_scikit_ovr:       4198.317662  0.876057\n",
       "17           XGBClassifier:         15.229001  0.862817"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "\n",
    "results = get_tests_result_ovr(X_train_v, X_test_v, y_train, y_test)\n",
    "results\n",
    "#### ... pasta 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 16 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: CountVectorizer\n",
    "* Abordagem One vs Rest\n",
    "* Staking Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>207.553618</td>\n",
       "      <td>0.868334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>8.248807</td>\n",
       "      <td>0.802501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>15.962435</td>\n",
       "      <td>0.820767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>92.246801</td>\n",
       "      <td>0.397205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>144.855197</td>\n",
       "      <td>0.791467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>86.603116</td>\n",
       "      <td>0.787912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>107.395313</td>\n",
       "      <td>0.880348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>283.766477</td>\n",
       "      <td>0.881819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>3.512897</td>\n",
       "      <td>0.852274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>468.389114</td>\n",
       "      <td>0.863798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>1951.044009</td>\n",
       "      <td>0.863798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.872134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>5673.325434</td>\n",
       "      <td>0.883168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>6.408840</td>\n",
       "      <td>0.869192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:        207.553618  0.868334\n",
       "1       AdaBoostClassifier:          8.248807  0.802501\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:         15.962435  0.820767\n",
       "5               GaussianNB:         92.246801  0.397205\n",
       "6              BernoulliNB:        144.855197  0.791467\n",
       "7            MultinomialNB:         86.603116  0.787912\n",
       "8   RandomForestClassifier:        107.395313  0.880348\n",
       "9     ExtraTreesClassifier:        283.766477  0.881819\n",
       "10      LogisticRegression:          3.512897  0.852274\n",
       "11                     svm:        468.389114  0.863798\n",
       "12                 svm_rbf:       1951.044009  0.863798\n",
       "13              stacking_1:          0.000000  0.872134\n",
       "14              stacking_2:          0.000000  0.866005\n",
       "15              stacking_3:          0.000000  0.884516\n",
       "16     Stacking_scikit_ovr:       5673.325434  0.883168\n",
       "17           XGBClassifier:          6.408840  0.869192"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "list_corpus = DATASET[\"RELATOCLIENTE_CLEAN\"].tolist()\n",
    "list_labels = DATASET[\"PROBLEMA\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, train_size=0.80, \n",
    "                                                                                random_state=28)\n",
    "X_train_v, count_vectorizer = cv(X_train)\n",
    "X_test_v = count_vectorizer.transform(X_test)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result_ovr(X_train_v, X_test_v, y_train, y_test)\n",
    "results\n",
    "#### ... pasta 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 17 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "* gensim.corpora.Dictionary e bag of words;\n",
    "* técnica para topic modelling: Latent Dirichlet Allocation (LDA)\n",
    "* 30 tópicos \n",
    "* Usando somente as colunas dos 30 tópicos criados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5428921568627451\n",
      "Acurácia: 0.5416666666666666\n",
      "Acurácia: 0.5379901960784313\n",
      "Acurácia: 0.5281862745098039\n",
      "Acurácia: 0.5306372549019608\n",
      "Acurácia: 0.5453431372549019\n",
      "Acurácia: 0.5379901960784313\n",
      "Acurácia: 0.5294117647058824\n",
      "Acurácia: 0.5232843137254902\n",
      "Acurácia: 0.5208333333333334\n",
      "Acurácia: 0.553921568627451\n",
      "Acurácia: 0.5294117647058824\n",
      "Acurácia: 0.5220588235294118\n",
      "Acurácia: 0.5294117647058824\n",
      "Acurácia: 0.5343137254901961\n",
      "Acurácia: 0.5490196078431373\n",
      "Acurácia: 0.5306372549019608\n",
      "Acurácia: 0.5232843137254902\n",
      "Acurácia: 0.5416666666666666\n",
      "Acurácia: 0.5232843137254902\n",
      "Acurácia: 0.5490196078431373\n",
      "Acurácia: 0.5171568627450981\n",
      "Acurácia: 0.5686274509803921\n",
      "Acurácia: 0.5392156862745098\n",
      "Acurácia: 0.5220588235294118\n",
      "Acurácia: 0.5453431372549019\n",
      "Acurácia: 0.5416666666666666\n",
      "Acurácia: 0.5134803921568627\n",
      "Acurácia: 0.5318627450980392\n",
      "Acurácia: 0.5281862745098039\n",
      "Acurácia: 0.5122549019607843\n",
      "Acurácia: 0.5257352941176471\n",
      "Acurácia: 0.5349693251533743\n",
      "Acurácia: 0.5730061349693252\n",
      "Acurácia: 0.5349693251533743\n",
      "Acurácia: 0.5214723926380368\n",
      "Acurácia: 0.5276073619631901\n",
      "Acurácia: 0.5472392638036809\n",
      "Acurácia: 0.5361963190184049\n",
      "Acurácia: 0.5374233128834356\n",
      "Acurácia: 0.5447852760736196\n",
      "Acurácia: 0.5570552147239264\n",
      "Acurácia: 0.49693251533742333\n",
      "Acurácia: 0.5226993865030675\n",
      "Acurácia: 0.5325153374233129\n",
      "Acurácia: 0.5190184049079755\n",
      "Acurácia: 0.5435582822085889\n",
      "Acurácia: 0.5190184049079755\n",
      "Acurácia: 0.558282208588957\n",
      "Acurácia: 0.5239263803680981\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "DATASET[\"RELATOCLIENTE_CLEAN_T\"] = list(sent_to_words(DATASET.RELATOCLIENTE_CLEAN.values.tolist()))\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(DATASET.RELATOCLIENTE_CLEAN_T.values.tolist())\n",
    "# Create Corpus\n",
    "texts = DATASET.RELATOCLIENTE_CLEAN_T.values.tolist()\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# number of topics\n",
    "num_topics = 30\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics,\n",
    "                                       workers=2)\n",
    "\n",
    "# DATASET with topics\n",
    "for a in range( num_topics ):\n",
    "    column = \"TP\" + str(a + 1)\n",
    "    DATASET[column] = \" \"\n",
    "\n",
    "for i in range(len(DATASET)):\n",
    "    top_topics = (\n",
    "        lda_model.get_document_topics(corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "    )\n",
    "    topic_vec = [top_topics[j][1] for j in range(num_topics)]\n",
    "    \n",
    "    for a in range(num_topics):\n",
    "        column = \"TP\" + str(a + 1)\n",
    "        DATASET[column].iloc[i] = topic_vec[a]\n",
    "\n",
    "column = []\n",
    "for a in range(num_topics):\n",
    "    column.append(\"TP\" + str(a + 1))\n",
    "\n",
    "X = np.array(DATASET[column])\n",
    "y = np.array(DATASET.PROBLEMA)        \n",
    "        \n",
    "kf = KFold(50, shuffle=True, random_state=42)\n",
    "\n",
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    \n",
    "    p_ac = metrics.accuracy_score(y_val,  y_pred)\n",
    "    print(\"Acurácia: \" + str(p_ac))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 18 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* técnica para topic modelling: Latent Dirichlet Allocation (LDA)\n",
    "* Usando \n",
    "    * 30 tópicos\n",
    "    * texto(TF-IDF) variando max_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features: 10 #Acurácia: 0.6388\n",
      "max_features: 20 #Acurácia: 0.6935\n",
      "max_features: 30 #Acurácia: 0.7036\n",
      "max_features: 40 #Acurácia: 0.7334\n",
      "max_features: 50 #Acurácia: 0.7369\n",
      "max_features: 60 #Acurácia: 0.7549\n",
      "max_features: 70 #Acurácia: 0.7585\n",
      "max_features: 80 #Acurácia: 0.7676\n",
      "max_features: 90 #Acurácia: 0.7690\n",
      "max_features: 100 #Acurácia: 0.7738\n",
      "max_features: 110 #Acurácia: 0.7787\n",
      "max_features: 120 #Acurácia: 0.7802\n",
      "max_features: 130 #Acurácia: 0.7826\n",
      "max_features: 140 #Acurácia: 0.7873\n",
      "max_features: 150 #Acurácia: 0.7878\n",
      "max_features: 160 #Acurácia: 0.7912\n",
      "max_features: 170 #Acurácia: 0.7956\n",
      "max_features: 180 #Acurácia: 0.7976\n",
      "max_features: 190 #Acurácia: 0.8009\n",
      "max_features: 200 #Acurácia: 0.8038\n",
      "max_features: 210 #Acurácia: 0.8064\n",
      "max_features: 220 #Acurácia: 0.8074\n",
      "max_features: 230 #Acurácia: 0.8118\n",
      "max_features: 240 #Acurácia: 0.8132\n",
      "max_features: 250 #Acurácia: 0.8160\n",
      "max_features: 260 #Acurácia: 0.8195\n",
      "max_features: 270 #Acurácia: 0.8209\n",
      "max_features: 280 #Acurácia: 0.8213\n",
      "max_features: 290 #Acurácia: 0.8215\n",
      "max_features: 300 #Acurácia: 0.8210\n",
      "max_features: 310 #Acurácia: 0.8252\n",
      "max_features: 320 #Acurácia: 0.8253\n",
      "max_features: 330 #Acurácia: 0.8291\n",
      "max_features: 340 #Acurácia: 0.8302\n",
      "max_features: 350 #Acurácia: 0.8320\n",
      "max_features: 360 #Acurácia: 0.8322\n",
      "max_features: 370 #Acurácia: 0.8329\n",
      "max_features: 380 #Acurácia: 0.8344\n",
      "max_features: 390 #Acurácia: 0.8333\n",
      "max_features: 400 #Acurácia: 0.8338\n",
      "max_features: 410 #Acurácia: 0.8346\n",
      "max_features: 420 #Acurácia: 0.8345\n",
      "max_features: 430 #Acurácia: 0.8355\n",
      "max_features: 440 #Acurácia: 0.8367\n",
      "max_features: 450 #Acurácia: 0.8366\n",
      "max_features: 460 #Acurácia: 0.8368\n",
      "max_features: 470 #Acurácia: 0.8389\n",
      "max_features: 480 #Acurácia: 0.8388\n",
      "max_features: 490 #Acurácia: 0.8385\n",
      "max_features: 500 #Acurácia: 0.8398\n",
      "max_features: 510 #Acurácia: 0.8390\n",
      "max_features: 520 #Acurácia: 0.8411\n",
      "max_features: 530 #Acurácia: 0.8405\n",
      "max_features: 540 #Acurácia: 0.8408\n",
      "max_features: 550 #Acurácia: 0.8410\n",
      "max_features: 560 #Acurácia: 0.8415\n",
      "max_features: 570 #Acurácia: 0.8410\n",
      "max_features: 580 #Acurácia: 0.8404\n",
      "max_features: 590 #Acurácia: 0.8414\n",
      "max_features: 600 #Acurácia: 0.8417\n",
      "max_features: 610 #Acurácia: 0.8411\n",
      "max_features: 620 #Acurácia: 0.8419\n",
      "max_features: 630 #Acurácia: 0.8426\n",
      "max_features: 640 #Acurácia: 0.8415\n",
      "max_features: 650 #Acurácia: 0.8416\n",
      "max_features: 660 #Acurácia: 0.8411\n",
      "max_features: 670 #Acurácia: 0.8410\n",
      "max_features: 680 #Acurácia: 0.8410\n",
      "max_features: 690 #Acurácia: 0.8420\n",
      "max_features: 700 #Acurácia: 0.8430\n",
      "max_features: 710 #Acurácia: 0.8426\n",
      "max_features: 720 #Acurácia: 0.8434\n",
      "max_features: 730 #Acurácia: 0.8425\n",
      "max_features: 740 #Acurácia: 0.8428\n",
      "max_features: 750 #Acurácia: 0.8441\n",
      "max_features: 760 #Acurácia: 0.8448\n",
      "max_features: 770 #Acurácia: 0.8453\n",
      "max_features: 780 #Acurácia: 0.8458\n",
      "max_features: 790 #Acurácia: 0.8448\n",
      "max_features: 800 #Acurácia: 0.8446\n",
      "max_features: 810 #Acurácia: 0.8438\n",
      "max_features: 820 #Acurácia: 0.8443\n",
      "max_features: 830 #Acurácia: 0.8443\n",
      "max_features: 840 #Acurácia: 0.8447\n",
      "max_features: 850 #Acurácia: 0.8452\n",
      "max_features: 860 #Acurácia: 0.8459\n",
      "max_features: 870 #Acurácia: 0.8454\n",
      "max_features: 880 #Acurácia: 0.8455\n",
      "max_features: 890 #Acurácia: 0.8454\n",
      "max_features: 900 #Acurácia: 0.8460\n",
      "max_features: 910 #Acurácia: 0.8468\n",
      "max_features: 920 #Acurácia: 0.8466\n",
      "max_features: 930 #Acurácia: 0.8468\n",
      "max_features: 940 #Acurácia: 0.8465\n",
      "max_features: 950 #Acurácia: 0.8466\n",
      "max_features: 960 #Acurácia: 0.8463\n",
      "max_features: 970 #Acurácia: 0.8461\n",
      "max_features: 980 #Acurácia: 0.8463\n",
      "max_features: 990 #Acurácia: 0.8457\n"
     ]
    }
   ],
   "source": [
    "for a in range(10, 1000 , 10):\n",
    "    vectorizer = TfidfVectorizer( max_features= a)\n",
    "    XX = vectorizer.fit_transform(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "    yy = DATASET[\"PROBLEMA\"]\n",
    "    XXX = hstack((XX, X.astype(float)))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split( XXX,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    Y_previsto_LR = lr.predict(X_test)\n",
    "\n",
    "    # Análise da previsão\n",
    "    p_ac = metrics.accuracy_score(y_test, np.floor( Y_previsto_LR) )\n",
    "    print(\"max_features: \"+ str(a) + \" \" + \"#Acurácia: {:.4f}\".format(p_ac) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 19 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* técnica para topic modelling: Latent Dirichlet Allocation (LDA)\n",
    "* Usando \n",
    "    * max_features  = 870\n",
    "    * Variando número de tópicos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_topics: 2 #Acurácia: 0.8453\n",
      "num_topics: 6 #Acurácia: 0.8458\n",
      "num_topics: 10 #Acurácia: 0.8454\n",
      "num_topics: 14 #Acurácia: 0.8459\n",
      "num_topics: 18 #Acurácia: 0.8474\n",
      "num_topics: 22 #Acurácia: 0.8464\n",
      "num_topics: 26 #Acurácia: 0.8465\n",
      "num_topics: 30 #Acurácia: 0.8465\n",
      "num_topics: 34 #Acurácia: 0.8471\n",
      "num_topics: 38 #Acurácia: 0.8468\n",
      "num_topics: 42 #Acurácia: 0.8492\n",
      "num_topics: 46 #Acurácia: 0.8461\n",
      "num_topics: 50 #Acurácia: 0.8468\n",
      "num_topics: 54 #Acurácia: 0.8482\n",
      "num_topics: 58 #Acurácia: 0.8479\n"
     ]
    }
   ],
   "source": [
    "for num_topics in range(2, 60 , 4):\n",
    "\n",
    "# Build LDA model\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics,\n",
    "                                       workers=2)\n",
    "    rev_train = DATASET\n",
    "    lda_train = lda_model\n",
    "\n",
    "\n",
    "    for a in range( num_topics ):\n",
    "        column = \"TP\" + str(a + 1)\n",
    "        rev_train[column] = \" \"\n",
    "\n",
    "    for i in range(len(rev_train)):\n",
    "        top_topics = (\n",
    "            lda_train.get_document_topics(corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "        )\n",
    "        topic_vec = [top_topics[j][1] for j in range(num_topics)]\n",
    "    \n",
    "        for a in range(num_topics):\n",
    "            column = \"TP\" + str(a + 1)\n",
    "            rev_train[column].iloc[i] = topic_vec[a]\n",
    "         \n",
    "    column = []\n",
    "    for a in range(num_topics):\n",
    "        column.append(\"TP\" + str(a + 1))\n",
    "\n",
    "    X = np.array(rev_train[column])\n",
    "    y = np.array(rev_train.PROBLEMA)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer( max_features= 930)\n",
    "    XX = vectorizer.fit_transform(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "    yy = DATASET[\"PROBLEMA\"]\n",
    "    XXX = hstack((XX, X.astype(float)))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split( XXX,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    Y_previsto_LR = lr.predict(X_test)\n",
    "\n",
    "    # Análise da previsão\n",
    "    p_ac = metrics.accuracy_score(y_test, np.floor( Y_previsto_LR) )\n",
    "    print(\"num_topics: \"+ str(num_topics) + \" \" + \"#Acurácia: {:.4f}\".format(p_ac) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 20 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* gensim.similarities\t\n",
    "    * Word Embedding Similarity Index\n",
    "* Similaridade entre as string escolhidas para representar as classes de problemas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 22774/22774 [00:04<00:00, 5080.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>44.011303</td>\n",
       "      <td>0.855584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>1.551394</td>\n",
       "      <td>0.748192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>980.843357</td>\n",
       "      <td>0.870663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>1019.340667</td>\n",
       "      <td>0.872747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>3.955566</td>\n",
       "      <td>0.833885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>23.041739</td>\n",
       "      <td>0.455437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>52.897381</td>\n",
       "      <td>0.781170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>43.558101</td>\n",
       "      <td>0.778718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>45.540468</td>\n",
       "      <td>0.871889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>117.374906</td>\n",
       "      <td>0.875812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>2.851230</td>\n",
       "      <td>0.847616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>91.926883</td>\n",
       "      <td>0.856565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>409.949159</td>\n",
       "      <td>0.856565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.872870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1506.702345</td>\n",
       "      <td>0.879490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>5.381871</td>\n",
       "      <td>0.866127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>113.230405</td>\n",
       "      <td>0.880348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         44.011303  0.855584\n",
       "1       AdaBoostClassifier:          1.551394  0.748192\n",
       "2     Voting_LR3_SVC1_ETC2:        980.843357  0.870663\n",
       "3     Voting_LR1_SVC1_ETC1:       1019.340667  0.872747\n",
       "4   DecisionTreeClassifier:          3.955566  0.833885\n",
       "5               GaussianNB:         23.041739  0.455437\n",
       "6              BernoulliNB:         52.897381  0.781170\n",
       "7            MultinomialNB:         43.558101  0.778718\n",
       "8   RandomForestClassifier:         45.540468  0.871889\n",
       "9     ExtraTreesClassifier:        117.374906  0.875812\n",
       "10      LogisticRegression:          2.851230  0.847616\n",
       "11                     svm:         91.926883  0.856565\n",
       "12                 svm_rbf:        409.949159  0.856565\n",
       "13              stacking_1:          0.000000  0.872870\n",
       "14              stacking_2:          0.000000  0.873238\n",
       "15              stacking_3:          0.000000  0.877651\n",
       "16         Stacking_scikit:       1506.702345  0.879490\n",
       "17           XGBClassifier:          5.381871  0.866127\n",
       "18                  OvR_RF:        113.230405  0.880348"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "DATASET[\"RELATOCLIENTE_CLEAN_T\"] = list(sent_to_words(DATASET.RELATOCLIENTE_CLEAN.values.tolist()))\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(DATASET.RELATOCLIENTE_CLEAN_T.values.tolist())\n",
    "# Create Corpus\n",
    "texts = DATASET.RELATOCLIENTE_CLEAN_T.values.tolist()\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "dictionary = Dictionary(DATASET.RELATOCLIENTE_CLEAN_T.values.tolist() )\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "w2v_model = Word2Vec( DATASET.RELATOCLIENTE_CLEAN_T.values.tolist(), workers=2, min_count=5, seed=12345)\n",
    "similarity_index = WordEmbeddingSimilarityIndex(w2v_model.wv)\n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf, nonzero_limit=100)\n",
    "\n",
    "s_modem_sem_sincronismo = \"conexao internet massiva sincronismo modem status sucesso testes procedimento telefone\".lower().split()\n",
    "s_massiva = \"massiva rede interrupcao ntt aberto primaria prazo gpon rftth\".lower().split()\n",
    "s_modem_sincronizado_e_autenticado = \"conexao internet modem procedimento massiva sucesso sincronizado status acesso testes\".lower().split()\n",
    "s_parametros_ruins = \"status attenuation margin parametros noise ont indicator conexao velocidade ruins\".lower().split()\n",
    "s_baixa_velocidade = \"ping upload download velocidade teste lentidao testes baixa cabo reclama\".lower().split()\n",
    "s_queda_intermitencia = \"quedas status conexao reinit internet attenuation ont ngasp power procedimentos\".lower().split()\n",
    "\n",
    "s_modem_sem_sincronismo = id2word.doc2bow(s_modem_sem_sincronismo)\n",
    "s_massiva = id2word.doc2bow(s_massiva)\n",
    "s_modem_sincronizado_e_autenticado = id2word.doc2bow(s_modem_sincronizado_e_autenticado)\n",
    "s_parametros_ruins = id2word.doc2bow(s_parametros_ruins)\n",
    "s_baixa_velocidade = id2word.doc2bow(s_baixa_velocidade)\n",
    "s_queda_intermitencia = id2word.doc2bow(s_queda_intermitencia)\n",
    "\n",
    "s0 = s_modem_sem_sincronismo\n",
    "s1 = s_massiva\n",
    "s2 = s_modem_sincronizado_e_autenticado\n",
    "s3 = s_parametros_ruins\n",
    "s4 = s_baixa_velocidade\n",
    "s5 = s_queda_intermitencia\n",
    "\n",
    "ss = [s0, s1, s2, s3, s4, s5]\n",
    "\n",
    "DATASET[\"S0\"] = 0.0\n",
    "DATASET[\"S1\"] = 0.0\n",
    "DATASET[\"S2\"] = 0.0\n",
    "DATASET[\"S3\"] = 0.0\n",
    "DATASET[\"S4\"] = 0.0\n",
    "DATASET[\"S5\"] = 0.0\n",
    "\n",
    "for a in range(len(DATASET)):\n",
    "    doc_vec = DATASET.iloc(0)[a][3]\n",
    "    doc_bow = id2word.doc2bow( doc_vec)\n",
    "        \n",
    "    DATASET[\"S0\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s0, normalized=(True, True))\n",
    "    DATASET[\"S1\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s1, normalized=(True, True))\n",
    "    DATASET[\"S2\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s2, normalized=(True, True))\n",
    "    DATASET[\"S3\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s3, normalized=(True, True))\n",
    "    DATASET[\"S4\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s4, normalized=(True, True))\n",
    "    DATASET[\"S5\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s5, normalized=(True, True))\n",
    "\n",
    "X = np.array(DATASET[[\"S0\", \"S1\", \"S2\", \"S3\", \"S4\", \"S5\" ]])\n",
    "y = np.array(DATASET.PROBLEMA)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X,\n",
    "                                                     y, \n",
    "                                                     train_size=0.80, random_state=28)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 21 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* gensim.similarities\t\n",
    "    * Word Embedding Similarity Index\n",
    "* teste usando\n",
    "    * Colunas de similaridade\n",
    "    * Texto (TF-IDF) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features: 100 #Acurácia: 0.7737\n",
      "max_features: 150 #Acurácia: 0.7858\n",
      "max_features: 200 #Acurácia: 0.8026\n",
      "max_features: 250 #Acurácia: 0.8156\n",
      "max_features: 300 #Acurácia: 0.8232\n",
      "max_features: 350 #Acurácia: 0.8290\n",
      "max_features: 400 #Acurácia: 0.8323\n",
      "max_features: 450 #Acurácia: 0.8366\n",
      "max_features: 500 #Acurácia: 0.8383\n",
      "max_features: 550 #Acurácia: 0.8423\n",
      "max_features: 600 #Acurácia: 0.8430\n",
      "max_features: 650 #Acurácia: 0.8442\n",
      "max_features: 700 #Acurácia: 0.8446\n",
      "max_features: 750 #Acurácia: 0.8458\n",
      "max_features: 800 #Acurácia: 0.8460\n",
      "max_features: 850 #Acurácia: 0.8453\n",
      "max_features: 900 #Acurácia: 0.8464\n",
      "max_features: 950 #Acurácia: 0.8474\n",
      "max_features: 1000 #Acurácia: 0.8459\n",
      "max_features: 1050 #Acurácia: 0.8471\n",
      "max_features: 1100 #Acurácia: 0.8476\n",
      "max_features: 1150 #Acurácia: 0.8487\n",
      "max_features: 1200 #Acurácia: 0.8492\n",
      "max_features: 1250 #Acurácia: 0.8480\n",
      "max_features: 1300 #Acurácia: 0.8482\n",
      "max_features: 1350 #Acurácia: 0.8486\n",
      "max_features: 1400 #Acurácia: 0.8491\n",
      "max_features: 1450 #Acurácia: 0.8493\n",
      "max_features: 1500 #Acurácia: 0.8482\n",
      "max_features: 1550 #Acurácia: 0.8484\n",
      "max_features: 1600 #Acurácia: 0.8486\n",
      "max_features: 1650 #Acurácia: 0.8486\n",
      "max_features: 1700 #Acurácia: 0.8495\n",
      "max_features: 1750 #Acurácia: 0.8490\n",
      "max_features: 1800 #Acurácia: 0.8495\n",
      "max_features: 1850 #Acurácia: 0.8496\n",
      "max_features: 1900 #Acurácia: 0.8491\n",
      "max_features: 1950 #Acurácia: 0.8491\n"
     ]
    }
   ],
   "source": [
    "for a in range(100, 2000, 50):\n",
    "    vectorizer = TfidfVectorizer( max_features= a)\n",
    "    XX = vectorizer.fit_transform(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "    XXX = hstack((XX, X.astype(float)))\n",
    "    y = np.array(DATASET.PROBLEMA)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split( XXX,\n",
    "                                                     y, \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "    \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "    lr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    Y_previsto_LR = lr.predict(X_test)\n",
    "\n",
    "    # Análise da previsão\n",
    "    p_ac = metrics.accuracy_score(y_test, np.floor( Y_previsto_LR) )\n",
    "    print(\"max_features: \"+ str(a) + \" \" + \"#Acurácia: {:.4f}\".format(p_ac) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 22 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* gensim.similarities\t\n",
    "    * Word Embedding Similarity Index\n",
    "* teste usando\n",
    "    * 6 colunas de similaridade\n",
    "    * 6 tópicos ( topic modelling LDA )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>51.072125</td>\n",
       "      <td>0.710433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>12.541309</td>\n",
       "      <td>0.672796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>2.416579</td>\n",
       "      <td>0.696580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.062499</td>\n",
       "      <td>0.513547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.046858</td>\n",
       "      <td>0.206939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.031240</td>\n",
       "      <td>0.476768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>19.020178</td>\n",
       "      <td>0.785828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>11.446131</td>\n",
       "      <td>0.788770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.911223</td>\n",
       "      <td>0.651465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>97.317969</td>\n",
       "      <td>0.688734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>478.813243</td>\n",
       "      <td>0.688734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.706142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.784602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>559.711235</td>\n",
       "      <td>0.791100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>8.606571</td>\n",
       "      <td>0.784970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         51.072125  0.710433\n",
       "1       AdaBoostClassifier:         12.541309  0.672796\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          2.416579  0.696580\n",
       "5               GaussianNB:          0.062499  0.513547\n",
       "6              BernoulliNB:          0.046858  0.206939\n",
       "7            MultinomialNB:          0.031240  0.476768\n",
       "8   RandomForestClassifier:         19.020178  0.785828\n",
       "9     ExtraTreesClassifier:         11.446131  0.788770\n",
       "10      LogisticRegression:          0.911223  0.651465\n",
       "11                     svm:         97.317969  0.688734\n",
       "12                 svm_rbf:        478.813243  0.688734\n",
       "13              stacking_1:          0.000000  0.720363\n",
       "14              stacking_2:          0.000000  0.706142\n",
       "15              stacking_3:          0.000000  0.784602\n",
       "16     Stacking_scikit_ovr:        559.711235  0.791100\n",
       "17           XGBClassifier:          8.606571  0.784970"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = 6\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics= 6,\n",
    "                                       workers=2)\n",
    "\n",
    "rev_train = DATASET\n",
    "lda_train = lda_model\n",
    "\n",
    "for a in range( num_topics ):\n",
    "    column = \"TP\" + str(a + 1)\n",
    "    rev_train[column] = \" \"\n",
    "\n",
    "for i in range(len(rev_train)):\n",
    "    top_topics = (\n",
    "        lda_train.get_document_topics(corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "    )\n",
    "    topic_vec = [top_topics[j][1] for j in range(num_topics)]\n",
    "    \n",
    "    for a in range(num_topics):\n",
    "        column = \"TP\" + str(a + 1)\n",
    "        rev_train[column].iloc[i] = topic_vec[a]\n",
    "\n",
    "column = []\n",
    "for a in range(num_topics):\n",
    "    column.append(\"TP\" + str(a + 1))\n",
    "\n",
    "X_t = np.array(rev_train[column])\n",
    "y = np.array(rev_train.PROBLEMA)\n",
    "\n",
    "XXX = np.append(X_t.astype(float), X, axis=1).astype(float)\n",
    "y = np.array(DATASET.PROBLEMA)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( XXX,\n",
    "                                                     y, \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result_ovr(X_train, X_test, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 23 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Comparação\n",
    "    * CountVectorizer(nível word, char e ngrams)\n",
    "    * Tf-IDF (nível word, char e ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "DATASET[\"RELATOCLIENTE_CLEAN_T\"] = list(sent_to_words(DATASET.RELATOCLIENTE_CLEAN.values.tolist()))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( DATASET[\"RELATOCLIENTE_CLEAN\"] ,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "# CountVectorizer word level\n",
    "# X_train_count_vect_w, X_test_count_vect_w, y_train, y_test\n",
    "count_vect_w = CountVectorizer(analyzer='word')\n",
    "count_vect_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_w =  count_vect_w.transform(X_train)\n",
    "X_test_count_vect_w =  count_vect_w.transform(X_test)\n",
    "\n",
    "# CountVectorizer word ngram level\n",
    "# X_train_count_vect_w_ngram, X_test_count_vect_w_ngram, y_train, y_test\n",
    "count_vect_w_ngram = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "count_vect_w_ngram.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_w_ngram =  count_vect_w_ngram.transform(X_train)\n",
    "X_test_count_vect_w_ngram =  count_vect_w_ngram.transform(X_test)\n",
    "\n",
    "# CountVectorizer char level\n",
    "# X_train_count_vect_char, X_test_count_vect_char, y_train, y_test\n",
    "count_vect_char = CountVectorizer(analyzer='char', max_features=5000)\n",
    "count_vect_char.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_char =  count_vect_char.transform(X_train)\n",
    "X_test_count_vect_char =  count_vect_char.transform(X_test)\n",
    "\n",
    "# CountVectorizer char ngram level\n",
    "# X_train_count_vect_char_ngram, X_test_count_vect_char_ngram, y_train, y_test\n",
    "count_vect_char_ngram = CountVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "count_vect_char_ngram.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_char_ngram =  count_vect_char_ngram.transform(X_train)\n",
    "X_test_count_vect_char_ngram =  count_vect_char_ngram.transform(X_test)\n",
    "\n",
    "#########################################\n",
    "\n",
    "# tf-idf word level\n",
    "# X_train_tfidf_w, X_test_tfidf_w, y_train, y_test\n",
    "tfidf_w = TfidfVectorizer(analyzer='word', max_features=500)\n",
    "tfidf_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_w =  tfidf_w.transform(X_train)\n",
    "X_test_tfidf_w =  tfidf_w.transform(X_test)\n",
    "\n",
    "# tf-idf word ngram level  \n",
    "# X_train_tfidf_w_ngram, X_test_tfidf_w_ngram, y_train, y_test\n",
    "tfidf_w_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_w_ngram.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_w_ngram =  tfidf_w_ngram.transform(X_train)\n",
    "X_test_tfidf_w_ngram =  tfidf_w_ngram.transform(X_test)\n",
    "\n",
    "# tf-idf char level \n",
    "# X_train_tfidf_char, X_test_tfidf_char, y_train, y_test\n",
    "tfidf_char = TfidfVectorizer(analyzer='char', max_features=5000)\n",
    "tfidf_char.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_char =  tfidf_char.transform(X_train) \n",
    "X_test_tfidf_char =  tfidf_char.transform(X_test)\n",
    "\n",
    "# tf-idf char ngram level\n",
    "# X_train_tfidf_char_ngram, X_test_tfidf_char_ngram, y_train, y_test\n",
    "tfidf_char_ngram = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_char_ngram.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_char_ngram =  tfidf_char_ngram.transform(X_train) \n",
    "X_test_tfidf_char_ngram =  tfidf_char_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-1 CountVectorizer word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>239.597515</td>\n",
       "      <td>0.866250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>196.052419</td>\n",
       "      <td>0.802501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>20.010902</td>\n",
       "      <td>0.822484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>114.567339</td>\n",
       "      <td>0.397205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>169.913872</td>\n",
       "      <td>0.791590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>103.386148</td>\n",
       "      <td>0.786073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>201.124133</td>\n",
       "      <td>0.878509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>754.164030</td>\n",
       "      <td>0.878877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>3.619460</td>\n",
       "      <td>0.852274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>496.036457</td>\n",
       "      <td>0.863308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>2012.444121</td>\n",
       "      <td>0.863308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>6501.258033</td>\n",
       "      <td>0.882432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>6.850762</td>\n",
       "      <td>0.869192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:        239.597515  0.866250\n",
       "1       AdaBoostClassifier:        196.052419  0.802501\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:         20.010902  0.822484\n",
       "5               GaussianNB:        114.567339  0.397205\n",
       "6              BernoulliNB:        169.913872  0.791590\n",
       "7            MultinomialNB:        103.386148  0.786073\n",
       "8   RandomForestClassifier:        201.124133  0.878509\n",
       "9     ExtraTreesClassifier:        754.164030  0.878877\n",
       "10      LogisticRegression:          3.619460  0.852274\n",
       "11                     svm:        496.036457  0.863308\n",
       "12                 svm_rbf:       2012.444121  0.863308\n",
       "13              stacking_1:          0.000000  0.871889\n",
       "14              stacking_2:          0.000000  0.865759\n",
       "15              stacking_3:          0.000000  0.882555\n",
       "16     Stacking_scikit_ovr:       6501.258033  0.882432\n",
       "17           XGBClassifier:          6.850762  0.869192"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_count_vect_w, X_test_count_vect_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-2 CountVectorizer word ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>129.513765</td>\n",
       "      <td>0.852274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>9.001002</td>\n",
       "      <td>0.746843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>15.046026</td>\n",
       "      <td>0.807405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>15.153743</td>\n",
       "      <td>0.471374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>26.385891</td>\n",
       "      <td>0.758122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>13.496485</td>\n",
       "      <td>0.779453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>111.225543</td>\n",
       "      <td>0.850190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>273.319567</td>\n",
       "      <td>0.846880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.992454</td>\n",
       "      <td>0.851661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>441.495551</td>\n",
       "      <td>0.845041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>1920.123233</td>\n",
       "      <td>0.845041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.855339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.852764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>3484.675709</td>\n",
       "      <td>0.859017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>6.239355</td>\n",
       "      <td>0.838298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:        129.513765  0.852274\n",
       "1       AdaBoostClassifier:          9.001002  0.746843\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:         15.046026  0.807405\n",
       "5               GaussianNB:         15.153743  0.471374\n",
       "6              BernoulliNB:         26.385891  0.758122\n",
       "7            MultinomialNB:         13.496485  0.779453\n",
       "8   RandomForestClassifier:        111.225543  0.850190\n",
       "9     ExtraTreesClassifier:        273.319567  0.846880\n",
       "10      LogisticRegression:          1.992454  0.851661\n",
       "11                     svm:        441.495551  0.845041\n",
       "12                 svm_rbf:       1920.123233  0.845041\n",
       "13              stacking_1:          0.000000  0.855339\n",
       "14              stacking_2:          0.000000  0.845777\n",
       "15              stacking_3:          0.000000  0.852764\n",
       "16     Stacking_scikit_ovr:       3484.675709  0.859017\n",
       "17           XGBClassifier:          6.239355  0.838298"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_count_vect_w_ngram, X_test_count_vect_w_ngram, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-3 CountVectorizer char level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>83.008878</td>\n",
       "      <td>0.673287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>10.459291</td>\n",
       "      <td>0.592375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>8.451981</td>\n",
       "      <td>0.645335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.156213</td>\n",
       "      <td>0.265294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.182806</td>\n",
       "      <td>0.422214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.066439</td>\n",
       "      <td>0.553022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>68.381751</td>\n",
       "      <td>0.760942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>214.710917</td>\n",
       "      <td>0.768052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.817640</td>\n",
       "      <td>0.603653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>237.432528</td>\n",
       "      <td>0.600466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>1309.467463</td>\n",
       "      <td>0.600466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>2295.292400</td>\n",
       "      <td>0.767684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>7.327477</td>\n",
       "      <td>0.750276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         83.008878  0.673287\n",
       "1       AdaBoostClassifier:         10.459291  0.592375\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          8.451981  0.645335\n",
       "5               GaussianNB:          0.156213  0.265294\n",
       "6              BernoulliNB:          0.182806  0.422214\n",
       "7            MultinomialNB:          0.066439  0.553022\n",
       "8   RandomForestClassifier:         68.381751  0.760942\n",
       "9     ExtraTreesClassifier:        214.710917  0.768052\n",
       "10      LogisticRegression:          1.817640  0.603653\n",
       "11                     svm:        237.432528  0.600466\n",
       "12                 svm_rbf:       1309.467463  0.600466\n",
       "13              stacking_1:          0.000000  0.679049\n",
       "14              stacking_2:          0.000000  0.654775\n",
       "15              stacking_3:          0.000000  0.759716\n",
       "16     Stacking_scikit_ovr:       2295.292400  0.767684\n",
       "17           XGBClassifier:          7.327477  0.750276"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_count_vect_char, X_test_count_vect_char, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-4 CountVectorizer char ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>525.134481</td>\n",
       "      <td>0.862817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>69.412013</td>\n",
       "      <td>0.813780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>103.053493</td>\n",
       "      <td>0.784357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>14.678028</td>\n",
       "      <td>0.343018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>27.131777</td>\n",
       "      <td>0.708103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>13.486414</td>\n",
       "      <td>0.706019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>206.212021</td>\n",
       "      <td>0.875812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>592.058095</td>\n",
       "      <td>0.877896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>8.670738</td>\n",
       "      <td>0.843938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>2695.548730</td>\n",
       "      <td>0.849822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>10761.042158</td>\n",
       "      <td>0.849822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.855707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.878877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>14020.388757</td>\n",
       "      <td>0.879122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>44.430461</td>\n",
       "      <td>0.877038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:        525.134481  0.862817\n",
       "1       AdaBoostClassifier:         69.412013  0.813780\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:        103.053493  0.784357\n",
       "5               GaussianNB:         14.678028  0.343018\n",
       "6              BernoulliNB:         27.131777  0.708103\n",
       "7            MultinomialNB:         13.486414  0.706019\n",
       "8   RandomForestClassifier:        206.212021  0.875812\n",
       "9     ExtraTreesClassifier:        592.058095  0.877896\n",
       "10      LogisticRegression:          8.670738  0.843938\n",
       "11                     svm:       2695.548730  0.849822\n",
       "12                 svm_rbf:      10761.042158  0.849822\n",
       "13              stacking_1:          0.000000  0.868211\n",
       "14              stacking_2:          0.000000  0.855707\n",
       "15              stacking_3:          0.000000  0.878877\n",
       "16     Stacking_scikit_ovr:      14020.388757  0.879122\n",
       "17           XGBClassifier:         44.430461  0.877038"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_count_vect_char_ngram, X_test_count_vect_char_ngram, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-5 tf-idf word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>79.921324</td>\n",
       "      <td>0.858281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>14.990985</td>\n",
       "      <td>0.800294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>20.666564</td>\n",
       "      <td>0.804217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>1.521257</td>\n",
       "      <td>0.421846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.939404</td>\n",
       "      <td>0.771730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.234411</td>\n",
       "      <td>0.772956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>52.655717</td>\n",
       "      <td>0.868579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>139.869122</td>\n",
       "      <td>0.875935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.363357</td>\n",
       "      <td>0.835111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>295.481270</td>\n",
       "      <td>0.872012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>1244.456551</td>\n",
       "      <td>0.872012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>2057.312865</td>\n",
       "      <td>0.877406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>15.177180</td>\n",
       "      <td>0.866863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         79.921324  0.858281\n",
       "1       AdaBoostClassifier:         14.990985  0.800294\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:         20.666564  0.804217\n",
       "5               GaussianNB:          1.521257  0.421846\n",
       "6              BernoulliNB:          0.939404  0.771730\n",
       "7            MultinomialNB:          0.234411  0.772956\n",
       "8   RandomForestClassifier:         52.655717  0.868579\n",
       "9     ExtraTreesClassifier:        139.869122  0.875935\n",
       "10      LogisticRegression:          1.363357  0.835111\n",
       "11                     svm:        295.481270  0.872012\n",
       "12                 svm_rbf:       1244.456551  0.872012\n",
       "13              stacking_1:          0.000000  0.871644\n",
       "14              stacking_2:          0.000000  0.866005\n",
       "15              stacking_3:          0.000000  0.875812\n",
       "16     Stacking_scikit_ovr:       2057.312865  0.877406\n",
       "17           XGBClassifier:         15.177180  0.866863"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_tfidf_w, X_test_tfidf_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-6 tf-idf word ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>137.921298</td>\n",
       "      <td>0.845409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>19.710509</td>\n",
       "      <td>0.749785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>60.369111</td>\n",
       "      <td>0.801888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>14.992407</td>\n",
       "      <td>0.493319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>7.904554</td>\n",
       "      <td>0.758122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>2.288663</td>\n",
       "      <td>0.792448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>110.199990</td>\n",
       "      <td>0.849454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>298.020694</td>\n",
       "      <td>0.853132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.766666</td>\n",
       "      <td>0.837685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>483.736077</td>\n",
       "      <td>0.843325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>2135.210961</td>\n",
       "      <td>0.843325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.856442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>3893.647557</td>\n",
       "      <td>0.858772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>20.587560</td>\n",
       "      <td>0.836705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:        137.921298  0.845409\n",
       "1       AdaBoostClassifier:         19.710509  0.749785\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:         60.369111  0.801888\n",
       "5               GaussianNB:         14.992407  0.493319\n",
       "6              BernoulliNB:          7.904554  0.758122\n",
       "7            MultinomialNB:          2.288663  0.792448\n",
       "8   RandomForestClassifier:        110.199990  0.849454\n",
       "9     ExtraTreesClassifier:        298.020694  0.853132\n",
       "10      LogisticRegression:          1.766666  0.837685\n",
       "11                     svm:        483.736077  0.843325\n",
       "12                 svm_rbf:       2135.210961  0.843325\n",
       "13              stacking_1:          0.000000  0.857668\n",
       "14              stacking_2:          0.000000  0.851539\n",
       "15              stacking_3:          0.000000  0.856442\n",
       "16     Stacking_scikit_ovr:       3893.647557  0.858772\n",
       "17           XGBClassifier:         20.587560  0.836705"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_tfidf_w_ngram, X_test_tfidf_w_ngram, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-7 tf-idf char level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>79.892709</td>\n",
       "      <td>0.671080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>23.039277</td>\n",
       "      <td>0.630011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>12.131545</td>\n",
       "      <td>0.627559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.141744</td>\n",
       "      <td>0.319603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.140565</td>\n",
       "      <td>0.422214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>0.540517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>77.553649</td>\n",
       "      <td>0.758980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>219.745392</td>\n",
       "      <td>0.769891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>1.568766</td>\n",
       "      <td>0.610764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>213.659915</td>\n",
       "      <td>0.672919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>1266.041957</td>\n",
       "      <td>0.672919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>2502.647633</td>\n",
       "      <td>0.773691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>26.778030</td>\n",
       "      <td>0.754076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:         79.892709  0.671080\n",
       "1       AdaBoostClassifier:         23.039277  0.630011\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:         12.131545  0.627559\n",
       "5               GaussianNB:          0.141744  0.319603\n",
       "6              BernoulliNB:          0.140565  0.422214\n",
       "7            MultinomialNB:          0.046896  0.540517\n",
       "8   RandomForestClassifier:         77.553649  0.758980\n",
       "9     ExtraTreesClassifier:        219.745392  0.769891\n",
       "10      LogisticRegression:          1.568766  0.610764\n",
       "11                     svm:        213.659915  0.672919\n",
       "12                 svm_rbf:       1266.041957  0.672919\n",
       "13              stacking_1:          0.000000  0.702219\n",
       "14              stacking_2:          0.000000  0.698051\n",
       "15              stacking_3:          0.000000  0.754444\n",
       "16     Stacking_scikit_ovr:       2502.647633  0.773691\n",
       "17           XGBClassifier:         26.778030  0.754076"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_tfidf_char, X_test_tfidf_char, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-8 tf-idf char ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>558.069123</td>\n",
       "      <td>0.858649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>205.661643</td>\n",
       "      <td>0.812676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>404.250487</td>\n",
       "      <td>0.777124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>15.814322</td>\n",
       "      <td>0.357607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>9.746896</td>\n",
       "      <td>0.708103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>2.095361</td>\n",
       "      <td>0.767562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>235.754543</td>\n",
       "      <td>0.867721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>653.506603</td>\n",
       "      <td>0.875077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>7.666459</td>\n",
       "      <td>0.843693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>3712.956743</td>\n",
       "      <td>0.872380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>14861.352978</td>\n",
       "      <td>0.872380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.872502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>18660.612724</td>\n",
       "      <td>0.879367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>198.480278</td>\n",
       "      <td>0.871154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:        558.069123  0.858649\n",
       "1       AdaBoostClassifier:        205.661643  0.812676\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:        404.250487  0.777124\n",
       "5               GaussianNB:         15.814322  0.357607\n",
       "6              BernoulliNB:          9.746896  0.708103\n",
       "7            MultinomialNB:          2.095361  0.767562\n",
       "8   RandomForestClassifier:        235.754543  0.867721\n",
       "9     ExtraTreesClassifier:        653.506603  0.875077\n",
       "10      LogisticRegression:          7.666459  0.843693\n",
       "11                     svm:       3712.956743  0.872380\n",
       "12                 svm_rbf:      14861.352978  0.872380\n",
       "13              stacking_1:          0.000000  0.872502\n",
       "14              stacking_2:          0.000000  0.865514\n",
       "15              stacking_3:          0.000000  0.877406\n",
       "16     Stacking_scikit_ovr:      18660.612724  0.879367\n",
       "17           XGBClassifier:        198.480278  0.871154"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_tfidf_char_ngram, X_test_tfidf_char_ngram, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 24 with the complete dataset \n",
    "* Other kind of problem (Motivo 3)\n",
    "* Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( DATASET[\"RELATOCLIENTE_CLEAN\"] ,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "# CountVectorizer word level\n",
    "# X_train_count_vect_w, X_test_count_vect_w, y_train, y_test\n",
    "count_vect_w = CountVectorizer(analyzer='word')\n",
    "count_vect_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"].astype('U').values)\n",
    "X_train_count_vect_w =  count_vect_w.transform(X_train.astype('U').values)\n",
    "X_test_count_vect_w =  count_vect_w.transform(X_test.astype('U').values)\n",
    "\n",
    "# tf-idf word level\n",
    "# X_train_tfidf_w, X_test_tfidf_w, y_train, y_test\n",
    "tfidf_w = TfidfVectorizer(analyzer='word')\n",
    "tfidf_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"].astype('U').values)\n",
    "X_train_tfidf_w =  tfidf_w.transform(X_train.astype('U').values)\n",
    "X_test_tfidf_w =  tfidf_w.transform(X_test.astype('U').values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sem Sincronismo     36400\n",
       "Exige Técnico       36400\n",
       "Parâmetros Ruins    36400\n",
       "Name: MOTIVO3, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET[\"MOTIVO3\"].value_counts()[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24 Count vectorizer word level\n",
    "* MemoryError: Unable to allocate 34.7 GiB for an array with shape (124080, 37545) and data type int64\n",
    "* GaussianNB removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests_result_ovr_24(X_train_v, X_test_v, y_train, y_test):\n",
    "    all_res = []\n",
    "    \n",
    "    ### RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1, n_jobs=5)\n",
    "    train_test_time, accuracy, Y_previsto_RF = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"RandomForestClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"RandomForestClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### ExtraTreesClassifier\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=0, n_jobs=5 )\n",
    "    train_test_time, accuracy, Y_previsto_ERT = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"ExtraTreesClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"ExtraTreesClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0, n_jobs=5)\n",
    "    train_test_time, accuracy, Y_previsto_LR = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"LogisticRegression: \" + str( accuracy) ) \n",
    "    all_res.append([\"LogisticRegression: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm\n",
    "    clf = svm.SVC()\n",
    "    train_test_time, accuracy, Y_previsto_SVM = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm: \", train_test_time, accuracy])\n",
    "        \n",
    "    ### Stacking 1\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_previsto_RF)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_1: \", 0 , accuracy])\n",
    "       \n",
    "    ### Stacking_scikit\n",
    "    clf1 = RandomForestClassifier(n_estimators=50, random_state=1, n_jobs=5)\n",
    "    clf2 = LogisticRegression(random_state=0, n_jobs=5)\n",
    "    clf3 = SVC()\n",
    "    clf4 = ExtraTreesClassifier(n_estimators=100, random_state=0, n_jobs=5)\n",
    "    estimators = [('rf', clf1), ('lr', clf2), ('svc', clf3), ('etc', clf4)]\n",
    "    ini = time.time()\n",
    "    clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression(), n_jobs=5)\n",
    "    \n",
    "    ovr = OneVsRestClassifier(clf)\n",
    "    ovr.fit(X_train_v, y_train)\n",
    "    Y_Previsto_stacking = ovr.predict(X_test_v)\n",
    "    \n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_Previsto_stacking)\n",
    "    all_res.append([\"Stacking_scikit_ovr: \", train_test_time , accuracy])\n",
    "    \n",
    "    ### XGBClassifier\n",
    "    Y_previsto_xgbc = 1\n",
    "    try:\n",
    "        clf = XGBClassifier(eval_metric='mlogloss')\n",
    "        train_test_time, accuracy, Y_previsto_xgbc = train_model_ovr(clf, X_train_v.tocsc(), X_test_v.tocsc(), y_train, y_test)\n",
    "        #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "        all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = XGBClassifier(eval_metric='mlogloss')\n",
    "        train_test_time, accuracy, Y_previsto_xgbc = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "        all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    return pd.DataFrame( all_res, columns=[\"ALGORITHM\",\"TRAIN_TEST_TIME\", \"ACCURACY\"]  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24-1 Count vectorizer word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>540.429988</td>\n",
       "      <td>0.892582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>1741.336369</td>\n",
       "      <td>0.891896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>3.920946</td>\n",
       "      <td>0.852610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm:</td>\n",
       "      <td>3132.753809</td>\n",
       "      <td>0.869963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.893727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>23994.915546</td>\n",
       "      <td>0.896566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>9.313779</td>\n",
       "      <td>0.864423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0  RandomForestClassifier:        540.429988  0.892582\n",
       "1    ExtraTreesClassifier:       1741.336369  0.891896\n",
       "2      LogisticRegression:          3.920946  0.852610\n",
       "3                     svm:       3132.753809  0.869963\n",
       "4              stacking_1:          0.000000  0.893727\n",
       "5     Stacking_scikit_ovr:      23994.915546  0.896566\n",
       "6           XGBClassifier:          9.313779  0.864423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr_24(X_train_count_vect_w, X_test_count_vect_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24-2 TF-IDF word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>474.769183</td>\n",
       "      <td>0.885256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>1729.176712</td>\n",
       "      <td>0.886401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>3.903657</td>\n",
       "      <td>0.855266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm:</td>\n",
       "      <td>3997.345918</td>\n",
       "      <td>0.887134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>27784.868036</td>\n",
       "      <td>0.892811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>29.563000</td>\n",
       "      <td>0.866850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0  RandomForestClassifier:        474.769183  0.885256\n",
       "1    ExtraTreesClassifier:       1729.176712  0.886401\n",
       "2      LogisticRegression:          3.903657  0.855266\n",
       "3                     svm:       3997.345918  0.887134\n",
       "4              stacking_1:          0.000000  0.888187\n",
       "5     Stacking_scikit_ovr:      27784.868036  0.892811\n",
       "6           XGBClassifier:         29.563000  0.866850"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr_24(X_train_tfidf_w, X_test_tfidf_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 25 with the complete dataset\n",
    "* Other kind of problem (Motivo 3)\n",
    "* Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/PMON2021-NLP\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( DATASET[\"RELATOCLIENTE_CLEAN\"] ,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "# CountVectorizer word level\n",
    "# X_train_count_vect_w, X_test_count_vect_w, y_train, y_test\n",
    "count_vect_w = CountVectorizer(analyzer='word')\n",
    "count_vect_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_w =  count_vect_w.transform(X_train)\n",
    "X_test_count_vect_w =  count_vect_w.transform(X_test)\n",
    "\n",
    "# tf-idf word level\n",
    "# X_train_tfidf_w, X_test_tfidf_w, y_train, y_test\n",
    "tfidf_w = TfidfVectorizer(analyzer='word')\n",
    "tfidf_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_w =  tfidf_w.transform(X_train)\n",
    "X_test_tfidf_w =  tfidf_w.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sem Sincronismo     192825\n",
       "Parâmetros Ruins     48775\n",
       "Exige Técnico        36456\n",
       "Name: MOTIVO3, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET[\"MOTIVO3\"].value_counts()[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25-1 Count vectorizer word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>693.860521</td>\n",
       "      <td>0.920629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>2123.462413</td>\n",
       "      <td>0.921042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>9.091674</td>\n",
       "      <td>0.894681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm:</td>\n",
       "      <td>14774.708380</td>\n",
       "      <td>0.911728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>36084.228401</td>\n",
       "      <td>0.924639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>22.439721</td>\n",
       "      <td>0.906027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0  RandomForestClassifier:        693.860521  0.920629\n",
       "1    ExtraTreesClassifier:       2123.462413  0.921042\n",
       "2      LogisticRegression:          9.091674  0.894681\n",
       "3                     svm:      14774.708380  0.911728\n",
       "4              stacking_1:          0.000000  0.922571\n",
       "5     Stacking_scikit_ovr:      36084.228401  0.924639\n",
       "6           XGBClassifier:         22.439721  0.906027"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr_24(X_train_count_vect_w, X_test_count_vect_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25-2 TF-IDF word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>551.986248</td>\n",
       "      <td>0.916565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>1999.468531</td>\n",
       "      <td>0.917338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>9.668607</td>\n",
       "      <td>0.891067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm:</td>\n",
       "      <td>21025.366353</td>\n",
       "      <td>0.917734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>46404.273352</td>\n",
       "      <td>0.923236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>64.996882</td>\n",
       "      <td>0.905560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0  RandomForestClassifier:        551.986248  0.916565\n",
       "1    ExtraTreesClassifier:       1999.468531  0.917338\n",
       "2      LogisticRegression:          9.668607  0.891067\n",
       "3                     svm:      21025.366353  0.917734\n",
       "4              stacking_1:          0.000000  0.919837\n",
       "5     Stacking_scikit_ovr:      46404.273352  0.923236\n",
       "6           XGBClassifier:         64.996882  0.905560"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr_24(X_train_tfidf_w, X_test_tfidf_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
