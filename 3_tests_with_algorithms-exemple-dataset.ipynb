{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter core     : 4.6.3\n",
      "jupyter-notebook : 6.1.4\n",
      "qtconsole        : 4.7.7\n",
      "ipython          : 7.19.0\n",
      "ipykernel        : 5.3.4\n",
      "jupyter client   : 6.1.7\n",
      "jupyter lab      : 2.2.6\n",
      "nbconvert        : 6.0.7\n",
      "ipywidgets       : 7.5.1\n",
      "nbformat         : 5.0.8\n",
      "traitlets        : 5.0.5\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from bert_serving.client import BertClient\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def vectorization_TF_IDF(DATASET, text_field_name, label_name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split( DATASET[text_field_name] ,\n",
    "                                                    DATASET[label_name], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_v = vectorizer.fit_transform(X_train.apply(str))\n",
    "    X_test_v = vectorizer.transform(X_test.apply(str))\n",
    "    \n",
    "    return X_train_v, X_test_v, y_train, y_test\n",
    "\n",
    "def saving_results(results, path, file_name):\n",
    "\n",
    "    results.to_csv(path + file_name,  index = False, sep=\";\")\n",
    "    \n",
    "def train_model(classifier, X_train_v, X_test_v, y_train, y_test):\n",
    "    ini = time.time()\n",
    "    classifier.fit(X_train_v, y_train)\n",
    "    predictions = classifier.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    \n",
    "    return fim-ini, metrics.accuracy_score(predictions, y_test), predictions\n",
    "\n",
    "def get_tests_result(X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    all_res = []\n",
    "    ### MLPClassifier\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, ), random_state=1, verbose=True)\n",
    "    train_test_time, accuracy, Y_Previsto_MLP = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"MLPClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"MLPClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### AdaBoostClassifier\n",
    "    clf = AdaBoostClassifier(n_estimators= 50, learning_rate=1)\n",
    "    train_test_time, accuracy, Y_Previsto_ada = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"AdaBoostClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"AdaBoostClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### Voting_LR3_SVC1_ETC2\n",
    "    ini = time.time()\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf5 = SVC(kernel='rbf', probability=True)\n",
    "    clf6 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    eclf = VotingClassifier(estimators=[ ('lr', clf2), ('svc', clf5), ('etc', clf6)], voting='soft', weights=[3, 1, 2])\n",
    "    clf2 = clf2.fit(X_train_v, y_train)\n",
    "    clf5 = clf5.fit(X_train_v, y_train)\n",
    "    clf6 = clf6.fit(X_train_v, y_train)\n",
    "    eclf = eclf.fit(X_train_v, y_train)\n",
    "    Y_previsto_vc1 = eclf.predict(X_test_v.toarray())\n",
    "    fim = time.time()\n",
    "    train_test_time = fim - ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_previsto_vc1)\n",
    "    #print( \"Voting_LR3_SVC1_ETC2: \" + str( accuracy) ) \n",
    "    all_res.append([\"Voting_LR3_SVC1_ETC2: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### Voting_LR1_SVC1_ETC1\n",
    "    ini = time.time()\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf5 = SVC(kernel='rbf', probability=True)\n",
    "    clf6 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    eclf = VotingClassifier(estimators=[ ('lr', clf2), ('svc', clf5), ('etc', clf6)], voting='soft', weights=[1, 1, 1])\n",
    "    clf2 = clf2.fit(X_train_v, y_train)\n",
    "    clf5 = clf5.fit(X_train_v, y_train)\n",
    "    clf6 = clf6.fit(X_train_v, y_train)\n",
    "    eclf = eclf.fit(X_train_v, y_train)\n",
    "    Y_previsto_vc2 = eclf.predict(X_test_v.toarray())\n",
    "    fim = time.time()\n",
    "    train_test_time = fim - ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_previsto_vc2)\n",
    "    #print( \"Voting_LR1_SVC1_ETC1: \" + str( accuracy) ) \n",
    "    all_res.append([\"Voting_LR1_SVC1_ETC1: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_DTC = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"DecisionTreeClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"DecisionTreeClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_G = train_model(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"GaussianNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"GaussianNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### BernoulliNB\n",
    "    clf = BernoulliNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_B = train_model(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"BernoulliNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"BernoulliNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### MultinomialNB\n",
    "    clf = MultinomialNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_M = train_model(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"MultinomialNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"MultinomialNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    train_test_time, accuracy, Y_previsto_RF = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"RandomForestClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"RandomForestClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### ExtraTreesClassifier\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_ERT = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"ExtraTreesClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"ExtraTreesClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_LR = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"LogisticRegression: \" + str( accuracy) ) \n",
    "    all_res.append([\"LogisticRegression: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm\n",
    "    clf = svm.SVC()\n",
    "    train_test_time, accuracy, Y_previsto_SVM = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm_rbf\n",
    "    clf = svm.SVC(kernel='rbf', probability=True)\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm_rbf: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm_rbf: \", train_test_time, accuracy])\n",
    "        \n",
    "    ### Stacking 1\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc1[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc2[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_1: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 2\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        #elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc1[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc2[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_2: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 3\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_vc1[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_vc2[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_3: \", 0 , accuracy]) \n",
    "    \n",
    "    ### Stacking_scikit\n",
    "    clf1 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf3 = SVC()\n",
    "    clf4 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    estimators = [('rf', clf1), ('lr', clf2), ('svc', clf3), ('etc', clf4)]\n",
    "    ini = time.time()\n",
    "    clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression(), n_jobs=None)\n",
    "    clf.fit(X_train_v, y_train)\n",
    "    Y_Previsto_stacking = clf.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_Previsto_stacking)\n",
    "    all_res.append([\"Stacking_scikit: \", train_test_time , accuracy])\n",
    "    \n",
    "    ### XGBClassifier\n",
    "    clf = XGBClassifier(eval_metric='mlogloss')\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model(clf, X_train_v.tocsc(), X_test_v.tocsc(), y_train, y_test)\n",
    "    #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### OneVsRestClassifier_RF\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    ovr = OneVsRestClassifier(clf)\n",
    "    ini = time.time()\n",
    "    ovr.fit(X_train_v, y_train)\n",
    "    Y_Previsto_OVR_RF = ovr.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(Y_Previsto_OVR_RF, y_test)\n",
    "    all_res.append([\"OvR_RF: \", train_test_time , accuracy])\n",
    "    \n",
    "    return pd.DataFrame( all_res, columns=[\"ALGORITHM\",\"TRAIN_TEST_TIME\", \"ACCURACY\"]  )\n",
    "\n",
    "def train_model_ovo(classifier, X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    ini = time.time()\n",
    "    ovo = OneVsOneClassifier(classifier)\n",
    "    ovo.fit(X_train_v, y_train)\n",
    "    predictions = ovo.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    \n",
    "    return fim-ini, metrics.accuracy_score(predictions, y_test), predictions\n",
    "\n",
    "def get_tests_result_ovo(X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    all_res = []\n",
    "    ### MLPClassifier\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, ), random_state=1, verbose=True)\n",
    "    train_test_time, accuracy, Y_Previsto_MLP = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"MLPClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"MLPClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### AdaBoostClassifier\n",
    "    clf = AdaBoostClassifier(n_estimators= 50, learning_rate=1)\n",
    "    train_test_time, accuracy, Y_Previsto_ada = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"AdaBoostClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"AdaBoostClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### Voting_LR3_SVC1_ETC2\n",
    "    all_res.append([\"Voting_LR3_SVC1_ETC2: \", 0 , 0 ])\n",
    "    \n",
    "    ### Voting_LR1_SVC1_ETC1\n",
    "    all_res.append([\"Voting_LR1_SVC1_ETC1: \", 0, 0])\n",
    "    \n",
    "    ### DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_DTC = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"DecisionTreeClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"DecisionTreeClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_G = train_model_ovo(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"GaussianNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"GaussianNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### BernoulliNB\n",
    "    clf = BernoulliNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_B = train_model_ovo(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"BernoulliNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"BernoulliNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### MultinomialNB\n",
    "    clf = MultinomialNB()\n",
    "    train_test_time, accuracy, Y_previsto_NB_M = train_model_ovo(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "    #print( \"MultinomialNB: \" + str( accuracy) ) \n",
    "    all_res.append([\"MultinomialNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    train_test_time, accuracy, Y_previsto_RF = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"RandomForestClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"RandomForestClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### ExtraTreesClassifier\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_ERT = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"ExtraTreesClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"ExtraTreesClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_LR = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"LogisticRegression: \" + str( accuracy) ) \n",
    "    all_res.append([\"LogisticRegression: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm\n",
    "    clf = svm.SVC()\n",
    "    train_test_time, accuracy, Y_previsto_SVM = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm_rbf\n",
    "    clf = svm.SVC(kernel='rbf', probability=True)\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model_ovo(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm_rbf: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm_rbf: \", train_test_time, accuracy])\n",
    "        \n",
    "    ### Stacking 1\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_1: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 2\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        #elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_2: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 3\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_3: \", 0 , accuracy]) \n",
    "    \n",
    "    ### Stacking_scikit\n",
    "    clf1 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf3 = SVC()\n",
    "    clf4 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    estimators = [('rf', clf1), ('lr', clf2), ('svc', clf3), ('etc', clf4)]\n",
    "    ini = time.time()\n",
    "    clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression(), n_jobs=None)\n",
    "    \n",
    "    ovo = OneVsOneClassifier(clf)\n",
    "    ovo.fit(X_train_v, y_train)\n",
    "    Y_Previsto_stacking = ovo.predict(X_test_v)\n",
    "    \n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_Previsto_stacking)\n",
    "    all_res.append([\"Stacking_scikit_ovo: \", train_test_time , accuracy])\n",
    "    \n",
    "    ### XGBClassifier\n",
    "    clf = XGBClassifier(eval_metric='mlogloss')\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model_ovo(clf, X_train_v.tocsc(), X_test_v.tocsc(), y_train, y_test)\n",
    "    #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    return pd.DataFrame( all_res, columns=[\"ALGORITHM\",\"TRAIN_TEST_TIME\", \"ACCURACY\"]  )\n",
    "    \n",
    "    \n",
    "def train_model_ovr(classifier, X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    ini = time.time()\n",
    "    ovr = OneVsRestClassifier(classifier)\n",
    "    try:\n",
    "        ovr.fit(X_train_v, y_train)\n",
    "    except:\n",
    "        ovr.fit(X_train_v.toarray(), y_train)\n",
    "    predictions = ovr.predict(X_test_v)\n",
    "    fim = time.time()\n",
    "    \n",
    "    return fim-ini, metrics.accuracy_score(predictions, y_test), predictions\n",
    "\n",
    "def get_tests_result_ovr(X_train_v, X_test_v, y_train, y_test):\n",
    "    \n",
    "    all_res = []    \n",
    "    ### MLPClassifier\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, ), random_state=1, verbose=True)\n",
    "    train_test_time, accuracy, Y_Previsto_MLP = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"MLPClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"MLPClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### AdaBoostClassifier\n",
    "    clf = AdaBoostClassifier(n_estimators= 50, learning_rate=1)\n",
    "    train_test_time, accuracy, Y_Previsto_ada = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"AdaBoostClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"AdaBoostClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### Voting_LR3_SVC1_ETC2\n",
    "    all_res.append([\"Voting_LR3_SVC1_ETC2: \", 0 , 0 ])\n",
    "    \n",
    "    ### Voting_LR1_SVC1_ETC1\n",
    "    all_res.append([\"Voting_LR1_SVC1_ETC1: \", 0, 0])\n",
    "    \n",
    "    ### DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_DTC = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"DecisionTreeClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"DecisionTreeClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### GaussianNB\n",
    "    Y_previsto_NB_G = 1\n",
    "    try:\n",
    "        clf = GaussianNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_G = train_model_ovr(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "        #print( \"GaussianNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"GaussianNB: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = GaussianNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_G = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"GaussianNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"GaussianNB: \", train_test_time, accuracy])\n",
    "      \n",
    "    \n",
    "    ### BernoulliNB\n",
    "    Y_previsto_NB_B = 1\n",
    "    try:\n",
    "        clf = BernoulliNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_B = train_model_ovr(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "        #print( \"BernoulliNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"BernoulliNB: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = BernoulliNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_B = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"BernoulliNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"BernoulliNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### MultinomialNB\n",
    "    Y_previsto_NB_M = 1\n",
    "    try:\n",
    "        clf = MultinomialNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_M = train_model_ovr(clf, X_train_v.toarray(), X_test_v.toarray(), y_train, y_test)\n",
    "        #print( \"MultinomialNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"MultinomialNB: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = MultinomialNB()\n",
    "        train_test_time, accuracy, Y_previsto_NB_M = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"MultinomialNB: \" + str( accuracy) ) \n",
    "        all_res.append([\"MultinomialNB: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    train_test_time, accuracy, Y_previsto_RF = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"RandomForestClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"RandomForestClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### ExtraTreesClassifier\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_ERT = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"ExtraTreesClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"ExtraTreesClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    train_test_time, accuracy, Y_previsto_LR = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"LogisticRegression: \" + str( accuracy) ) \n",
    "    all_res.append([\"LogisticRegression: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm\n",
    "    clf = svm.SVC()\n",
    "    train_test_time, accuracy, Y_previsto_SVM = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm_rbf\n",
    "    clf = svm.SVC(kernel='rbf', probability=True)\n",
    "    train_test_time, accuracy, Y_previsto_svc = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm_rbf: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm_rbf: \", train_test_time, accuracy])\n",
    "        \n",
    "    ### Stacking 1\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_1: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 2\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        #elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_2: \", 0 , accuracy])\n",
    "    \n",
    "    ### Stacking 3\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_Previsto_MLP)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_Previsto_MLP[a] ) )\n",
    "        #elements.append( np.floor( Y_Previsto_ada[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_DTC[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_G[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_NB_B[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_3: \", 0 , accuracy]) \n",
    "    \n",
    "    ### Stacking_scikit\n",
    "    clf1 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    clf2 = LogisticRegression(random_state=0)\n",
    "    clf3 = SVC()\n",
    "    clf4 = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    estimators = [('rf', clf1), ('lr', clf2), ('svc', clf3), ('etc', clf4)]\n",
    "    ini = time.time()\n",
    "    clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression(), n_jobs=None)\n",
    "    \n",
    "    ovr = OneVsRestClassifier(clf)\n",
    "    ovr.fit(X_train_v, y_train)\n",
    "    Y_Previsto_stacking = ovr.predict(X_test_v)\n",
    "    \n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_Previsto_stacking)\n",
    "    all_res.append([\"Stacking_scikit_ovr: \", train_test_time , accuracy])\n",
    "    \n",
    "    ### XGBClassifier\n",
    "    Y_previsto_xgbc = 1\n",
    "    try:\n",
    "        clf = XGBClassifier(eval_metric='mlogloss')\n",
    "        train_test_time, accuracy, Y_previsto_xgbc = train_model_ovr(clf, X_train_v.tocsc(), X_test_v.tocsc(), y_train, y_test)\n",
    "        #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "        all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = XGBClassifier(eval_metric='mlogloss')\n",
    "        train_test_time, accuracy, Y_previsto_xgbc = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "        all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    return pd.DataFrame( all_res, columns=[\"ALGORITHM\",\"TRAIN_TEST_TIME\", \"ACCURACY\"]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening exemple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RELATOCLIENTE</th>\n",
       "      <th>PROBLEMA</th>\n",
       "      <th>RELATOCLIENTE_CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cliente entrou em contato informando que está ...</td>\n",
       "      <td>Queda / Intermitência</td>\n",
       "      <td>cliente entrou contato informando esta sem sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLIENTE COM QUEDAS REALIZEI OS TESTE E ENCAMIN...</td>\n",
       "      <td>Queda / Intermitência</td>\n",
       "      <td>cliente com quedas realizei teste encaminhei s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cliente reclama de quedas e intermitência , pr...</td>\n",
       "      <td>Queda / Intermitência</td>\n",
       "      <td>cliente reclama quedas intermitencia procedime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLIENTE INFORMA QUE INTERNET ESTA COM QUEDAS H...</td>\n",
       "      <td>Queda / Intermitência</td>\n",
       "      <td>cliente informa internet esta com quedas mais ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       RELATOCLIENTE               PROBLEMA  \\\n",
       "0  cliente entrou em contato informando que está ...  Queda / Intermitência   \n",
       "1  CLIENTE COM QUEDAS REALIZEI OS TESTE E ENCAMIN...  Queda / Intermitência   \n",
       "2  Cliente reclama de quedas e intermitência , pr...  Queda / Intermitência   \n",
       "3  CLIENTE INFORMA QUE INTERNET ESTA COM QUEDAS H...  Queda / Intermitência   \n",
       "\n",
       "                                 RELATOCLIENTE_CLEAN  \n",
       "0  cliente entrou contato informando esta sem sin...  \n",
       "1  cliente com quedas realizei teste encaminhei s...  \n",
       "2  cliente reclama quedas intermitencia procedime...  \n",
       "3  cliente informa internet esta com quedas mais ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "DATASET.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 0 with the exemple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.079810</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.391004</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.388965</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.068843</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.123668</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.414818</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.286319</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.355073</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.236364  0.616667\n",
       "1       AdaBoostClassifier:          0.079810  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.391004  0.666667\n",
       "3     Voting_LR1_SVC1_ETC1:          0.388965  0.633333\n",
       "4   DecisionTreeClassifier:          0.004959  0.583333\n",
       "5               GaussianNB:          0.003989  0.500000\n",
       "6              BernoulliNB:          0.003027  0.616667\n",
       "7            MultinomialNB:          0.000970  0.633333\n",
       "8   RandomForestClassifier:          0.068843  0.666667\n",
       "9     ExtraTreesClassifier:          0.123668  0.633333\n",
       "10      LogisticRegression:          0.018945  0.700000\n",
       "11                     svm:          0.012970  0.633333\n",
       "12                 svm_rbf:          0.057845  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.666667\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.414818  0.616667\n",
       "17           XGBClassifier:          0.286319  0.683333\n",
       "18                  OvR_RF:          0.355073  0.633333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 with the complete dataset\n",
    "* Todas as palavras da base;\n",
    "* Removendo apenas stopwords;\n",
    "* 3000 registros para cada classe de problema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.235467</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.078812</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.385939</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.066850</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.125663</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.057847</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.386287</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.253291</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.351084</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.235467  0.616667\n",
       "1       AdaBoostClassifier:          0.078812  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.385972  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.385939  0.633333\n",
       "4   DecisionTreeClassifier:          0.003989  0.583333\n",
       "5               GaussianNB:          0.002992  0.500000\n",
       "6              BernoulliNB:          0.003015  0.616667\n",
       "7            MultinomialNB:          0.001000  0.633333\n",
       "8   RandomForestClassifier:          0.066850  0.666667\n",
       "9     ExtraTreesClassifier:          0.125663  0.633333\n",
       "10      LogisticRegression:          0.019949  0.700000\n",
       "11                     svm:          0.012964  0.633333\n",
       "12                 svm_rbf:          0.057847  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.386287  0.616667\n",
       "17           XGBClassifier:          0.253291  0.683333\n",
       "18                  OvR_RF:          0.351084  0.633333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 with the complete dataset\n",
    "* Todas as palavras da base;\n",
    "* Removendo apenas stopwords;\n",
    "* 7000 registros para cada classe de problema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.227183</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.078812</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.383978</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.385962</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.066850</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.120676</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013965</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.403210</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.266263</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.357069</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.227183  0.616667\n",
       "1       AdaBoostClassifier:          0.078812  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.383978  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.385962  0.633333\n",
       "4   DecisionTreeClassifier:          0.003991  0.583333\n",
       "5               GaussianNB:          0.002993  0.500000\n",
       "6              BernoulliNB:          0.002995  0.616667\n",
       "7            MultinomialNB:          0.001967  0.633333\n",
       "8   RandomForestClassifier:          0.066850  0.666667\n",
       "9     ExtraTreesClassifier:          0.120676  0.633333\n",
       "10      LogisticRegression:          0.019947  0.700000\n",
       "11                     svm:          0.013965  0.633333\n",
       "12                 svm_rbf:          0.057845  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.403210  0.616667\n",
       "17           XGBClassifier:          0.266263  0.683333\n",
       "18                  OvR_RF:          0.357069  0.633333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 with the complete dataset\n",
    "* Removendo as 6 palavras mais frequentes da base;\n",
    "* Removendo stopwords;\n",
    "* 3000 registros para cada classe de problema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.228389</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.077815</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.384975</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.385967</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.068808</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.123672</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.017951</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.057846</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.398267</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.254288</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.357045</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.228389  0.616667\n",
       "1       AdaBoostClassifier:          0.077815  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.384975  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.385967  0.633333\n",
       "4   DecisionTreeClassifier:          0.003990  0.583333\n",
       "5               GaussianNB:          0.002993  0.500000\n",
       "6              BernoulliNB:          0.001990  0.616667\n",
       "7            MultinomialNB:          0.002006  0.633333\n",
       "8   RandomForestClassifier:          0.068808  0.666667\n",
       "9     ExtraTreesClassifier:          0.123672  0.633333\n",
       "10      LogisticRegression:          0.017951  0.700000\n",
       "11                     svm:          0.012960  0.633333\n",
       "12                 svm_rbf:          0.057846  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.398267  0.616667\n",
       "17           XGBClassifier:          0.254288  0.683333\n",
       "18                  OvR_RF:          0.357045  0.633333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4 with the complete dataset\n",
    "* Base composta pelas 700 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 3000 registros para cada classe de problema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.233511</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.078811</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.389954</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.066853</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.121671</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.019948</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.058845</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.420197</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.259283</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.355050</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.233511  0.616667\n",
       "1       AdaBoostClassifier:          0.078811  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.385972  0.666667\n",
       "3     Voting_LR1_SVC1_ETC1:          0.389954  0.633333\n",
       "4   DecisionTreeClassifier:          0.003992  0.583333\n",
       "5               GaussianNB:          0.002992  0.500000\n",
       "6              BernoulliNB:          0.002992  0.616667\n",
       "7            MultinomialNB:          0.001967  0.633333\n",
       "8   RandomForestClassifier:          0.066853  0.666667\n",
       "9     ExtraTreesClassifier:          0.121671  0.633333\n",
       "10      LogisticRegression:          0.019948  0.700000\n",
       "11                     svm:          0.013963  0.633333\n",
       "12                 svm_rbf:          0.058845  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.666667\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.420197  0.616667\n",
       "17           XGBClassifier:          0.259283  0.683333\n",
       "18                  OvR_RF:          0.355050  0.633333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5 with the complete dataset\n",
    "* Base composta pelas 700 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 7000 registros para cada classe de problema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.393946</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.068787</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.128687</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.018946</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.060832</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.393308</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.266257</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.353055</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.238506  0.616667\n",
       "1       AdaBoostClassifier:          0.077820  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.385972  0.633333\n",
       "3     Voting_LR1_SVC1_ETC1:          0.393946  0.650000\n",
       "4   DecisionTreeClassifier:          0.003989  0.583333\n",
       "5               GaussianNB:          0.003962  0.500000\n",
       "6              BernoulliNB:          0.001994  0.616667\n",
       "7            MultinomialNB:          0.001025  0.633333\n",
       "8   RandomForestClassifier:          0.068787  0.666667\n",
       "9     ExtraTreesClassifier:          0.128687  0.633333\n",
       "10      LogisticRegression:          0.018946  0.700000\n",
       "11                     svm:          0.013968  0.633333\n",
       "12                 svm_rbf:          0.060832  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.633333\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.393308  0.616667\n",
       "17           XGBClassifier:          0.266257  0.683333\n",
       "18                  OvR_RF:          0.353055  0.633333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 6 with the complete dataset\n",
    "* Base composta pelas 4000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 3000 registros para cada classe de problema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.233650</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.077815</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.386969</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.391950</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.068842</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.122676</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.060840</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.401252</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.266260</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.351085</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.233650  0.616667\n",
       "1       AdaBoostClassifier:          0.077815  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.386969  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.391950  0.633333\n",
       "4   DecisionTreeClassifier:          0.003962  0.583333\n",
       "5               GaussianNB:          0.003018  0.500000\n",
       "6              BernoulliNB:          0.001996  0.616667\n",
       "7            MultinomialNB:          0.001999  0.633333\n",
       "8   RandomForestClassifier:          0.068842  0.666667\n",
       "9     ExtraTreesClassifier:          0.122676  0.633333\n",
       "10      LogisticRegression:          0.018948  0.700000\n",
       "11                     svm:          0.013967  0.633333\n",
       "12                 svm_rbf:          0.060840  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.401252  0.616667\n",
       "17           XGBClassifier:          0.266260  0.683333\n",
       "18                  OvR_RF:          0.351085  0.633333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 7 with the complete dataset\n",
    "* Base composta pelas 4000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 7000 registros para cada classe de problema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.226495</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.077815</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.386079</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.387963</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.124685</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.058819</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.396259</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.252296</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.353086</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.226495  0.616667\n",
       "1       AdaBoostClassifier:          0.077815  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.386079  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.387963  0.633333\n",
       "4   DecisionTreeClassifier:          0.003990  0.583333\n",
       "5               GaussianNB:          0.002987  0.500000\n",
       "6              BernoulliNB:          0.002999  0.616667\n",
       "7            MultinomialNB:          0.001980  0.633333\n",
       "8   RandomForestClassifier:          0.065808  0.666667\n",
       "9     ExtraTreesClassifier:          0.124685  0.633333\n",
       "10      LogisticRegression:          0.017956  0.700000\n",
       "11                     svm:          0.012965  0.633333\n",
       "12                 svm_rbf:          0.058819  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.396259  0.616667\n",
       "17           XGBClassifier:          0.252296  0.683333\n",
       "18                  OvR_RF:          0.353086  0.633333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 8 with the complete dataset\n",
    "* Todas as palavras da base;\n",
    "* Removendo stopwords;\n",
    "* BERT as service para português;\n",
    "* 3000 registros para cada classe de problema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train, X_test, y_train, y_test = train_test_split( DATASET[\"RELATOCLIENTE_CLEAN\"] ,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.8, random_state=42)\n",
    "\n",
    "bc = BertClient()\n",
    "X_train_bert = bc.encode(X_train.tolist())\n",
    "X_test_bert = bc.encode(X_test.tolist())\n",
    "X_train_v = X_train_bert.copy()\n",
    "X_test_v = X_test_bert.copy()\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 9 with the complete dataset\n",
    "* Base composta pelas 5000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.231558</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.079845</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.387992</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.386963</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.066849</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.018942</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.059838</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.408226</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.254296</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.364055</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.231558  0.616667\n",
       "1       AdaBoostClassifier:          0.079845  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.387992  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.386963  0.650000\n",
       "4   DecisionTreeClassifier:          0.003989  0.583333\n",
       "5               GaussianNB:          0.002992  0.500000\n",
       "6              BernoulliNB:          0.001989  0.616667\n",
       "7            MultinomialNB:          0.000998  0.633333\n",
       "8   RandomForestClassifier:          0.066849  0.666667\n",
       "9     ExtraTreesClassifier:          0.121677  0.633333\n",
       "10      LogisticRegression:          0.018942  0.700000\n",
       "11                     svm:          0.013964  0.633333\n",
       "12                 svm_rbf:          0.059838  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.408226  0.616667\n",
       "17           XGBClassifier:          0.254296  0.683333\n",
       "18                  OvR_RF:          0.364055  0.633333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10 with the complete dataset\n",
    "* Base composta pelas 10.000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.233443</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.078812</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.385944</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.387962</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.066844</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.122650</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.019978</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.402247</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.257288</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.352058</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.233443  0.616667\n",
       "1       AdaBoostClassifier:          0.078812  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.385944  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.387962  0.633333\n",
       "4   DecisionTreeClassifier:          0.003989  0.583333\n",
       "5               GaussianNB:          0.002992  0.500000\n",
       "6              BernoulliNB:          0.001995  0.616667\n",
       "7            MultinomialNB:          0.000997  0.633333\n",
       "8   RandomForestClassifier:          0.066844  0.666667\n",
       "9     ExtraTreesClassifier:          0.122650  0.633333\n",
       "10      LogisticRegression:          0.019978  0.700000\n",
       "11                     svm:          0.013958  0.633333\n",
       "12                 svm_rbf:          0.059840  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.402247  0.616667\n",
       "17           XGBClassifier:          0.257288  0.683333\n",
       "18                  OvR_RF:          0.352058  0.633333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 11 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: TF-IDF;\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.229497</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.077815</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.385973</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.388931</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.065855</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.121650</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.395360</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.252302</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.353079</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.229497  0.616667\n",
       "1       AdaBoostClassifier:          0.077815  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.385973  0.650000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.388931  0.633333\n",
       "4   DecisionTreeClassifier:          0.003989  0.583333\n",
       "5               GaussianNB:          0.002992  0.500000\n",
       "6              BernoulliNB:          0.002996  0.616667\n",
       "7            MultinomialNB:          0.000993  0.633333\n",
       "8   RandomForestClassifier:          0.065855  0.666667\n",
       "9     ExtraTreesClassifier:          0.121650  0.633333\n",
       "10      LogisticRegression:          0.018950  0.700000\n",
       "11                     svm:          0.013962  0.633333\n",
       "12                 svm_rbf:          0.057845  0.633333\n",
       "13              stacking_1:          0.000000  0.633333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16         Stacking_scikit:          1.395360  0.616667\n",
       "17           XGBClassifier:          0.252302  0.683333\n",
       "18                  OvR_RF:          0.353079  0.633333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 12 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: CountVectorizer;\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.165574</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.071836</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.413893</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.410902</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.065820</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.124638</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.033933</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.057822</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.454110</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.264293</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.355050</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.165574  0.650000\n",
       "1       AdaBoostClassifier:          0.071836  0.516667\n",
       "2     Voting_LR3_SVC1_ETC2:          0.413893  0.666667\n",
       "3     Voting_LR1_SVC1_ETC1:          0.410902  0.666667\n",
       "4   DecisionTreeClassifier:          0.002992  0.600000\n",
       "5               GaussianNB:          0.002989  0.516667\n",
       "6              BernoulliNB:          0.002995  0.616667\n",
       "7            MultinomialNB:          0.002993  0.633333\n",
       "8   RandomForestClassifier:          0.065820  0.600000\n",
       "9     ExtraTreesClassifier:          0.124638  0.650000\n",
       "10      LogisticRegression:          0.033933  0.683333\n",
       "11                     svm:          0.013962  0.650000\n",
       "12                 svm_rbf:          0.057822  0.650000\n",
       "13              stacking_1:          0.000000  0.683333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.666667\n",
       "16         Stacking_scikit:          1.454110  0.650000\n",
       "17           XGBClassifier:          0.264293  0.683333\n",
       "18                  OvR_RF:          0.355050  0.683333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "list_corpus = DATASET[\"RELATOCLIENTE_CLEAN\"].tolist()\n",
    "list_labels = DATASET[\"PROBLEMA\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, train_size=0.80, \n",
    "                                                                                random_state=28)\n",
    "X_train_v, count_vectorizer = cv(X_train)\n",
    "X_test_v = count_vectorizer.transform(X_test)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 13 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: CountVectorizer;\n",
    "* Stemmed_RSLP ( radicais das palavras)\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.159654</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.072805</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.415915</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.427855</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.068815</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.124666</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.483089</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.269252</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.358042</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.159654  0.650000\n",
       "1       AdaBoostClassifier:          0.072805  0.516667\n",
       "2     Voting_LR3_SVC1_ETC2:          0.415915  0.666667\n",
       "3     Voting_LR1_SVC1_ETC1:          0.427855  0.666667\n",
       "4   DecisionTreeClassifier:          0.002991  0.600000\n",
       "5               GaussianNB:          0.002992  0.516667\n",
       "6              BernoulliNB:          0.003989  0.616667\n",
       "7            MultinomialNB:          0.002993  0.633333\n",
       "8   RandomForestClassifier:          0.068815  0.600000\n",
       "9     ExtraTreesClassifier:          0.124666  0.650000\n",
       "10      LogisticRegression:          0.033910  0.683333\n",
       "11                     svm:          0.013962  0.650000\n",
       "12                 svm_rbf:          0.057845  0.650000\n",
       "13              stacking_1:          0.000000  0.683333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.666667\n",
       "16         Stacking_scikit:          1.483089  0.650000\n",
       "17           XGBClassifier:          0.269252  0.683333\n",
       "18                  OvR_RF:          0.358042  0.683333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "list_corpus = DATASET[\"RELATOCLIENTE_CLEAN\"].tolist()\n",
    "list_labels = DATASET[\"PROBLEMA\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, train_size=0.80, \n",
    "                                                                                random_state=28)\n",
    "X_train_v, count_vectorizer = cv(X_train)\n",
    "X_test_v = count_vectorizer.transform(X_test)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 14 with the complete dataset\n",
    "* Base composta pelas 10.000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: TF-IDF\n",
    "* Abordagem One vs One\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>1.300293</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>1.154915</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.025934</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.878645</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>1.483089</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.047874</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.092750</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovo:</td>\n",
       "      <td>13.577808</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.624330</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          1.300293  0.633333\n",
       "1       AdaBoostClassifier:          1.154915  0.650000\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.025934  0.550000\n",
       "5               GaussianNB:          0.025927  0.500000\n",
       "6              BernoulliNB:          0.025926  0.616667\n",
       "7            MultinomialNB:          0.015959  0.633333\n",
       "8   RandomForestClassifier:          0.878645  0.633333\n",
       "9     ExtraTreesClassifier:          1.483089  0.666667\n",
       "10      LogisticRegression:          0.060837  0.666667\n",
       "11                     svm:          0.047874  0.633333\n",
       "12                 svm_rbf:          0.092750  0.633333\n",
       "13              stacking_1:          0.000000  0.616667\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.616667\n",
       "16     Stacking_scikit_ovo:         13.577808  0.650000\n",
       "17           XGBClassifier:          0.624330  0.650000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result_ovo(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 15 with the complete dataset\n",
    "* Base composta pelas 10.000 palavras mais frequentes, removendo todas as palavras restantes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: TF-IDF\n",
    "* Abordagem One vs Rest\n",
    "* Staking personalizado: a moda das classificações de todos os algoritmos foi tomada como resultado da classificação;\n",
    "* Staking 1: todos os algoritmos;\n",
    "* Staking 2: 4 algoritmos com maior acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.788175</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.449820</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.346076</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.592418</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.036899</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.195473</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>6.691135</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.312165</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.788175  0.683333\n",
       "1       AdaBoostClassifier:          0.449820  0.650000\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.019951  0.550000\n",
       "5               GaussianNB:          0.016956  0.383333\n",
       "6              BernoulliNB:          0.013958  0.666667\n",
       "7            MultinomialNB:          0.006984  0.650000\n",
       "8   RandomForestClassifier:          0.346076  0.633333\n",
       "9     ExtraTreesClassifier:          0.592418  0.633333\n",
       "10      LogisticRegression:          0.036899  0.700000\n",
       "11                     svm:          0.051861  0.683333\n",
       "12                 svm_rbf:          0.195473  0.683333\n",
       "13              stacking_1:          0.000000  0.683333\n",
       "14              stacking_2:          0.000000  0.633333\n",
       "15              stacking_3:          0.000000  0.650000\n",
       "16     Stacking_scikit_ovr:          6.691135  0.650000\n",
       "17           XGBClassifier:          0.312165  0.683333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "X_train_v, X_test_v, y_train, y_test = vectorization_TF_IDF(DATASET,\n",
    "                                                            \"RELATOCLIENTE_CLEAN\",\n",
    "                                                           \"PROBLEMA\")\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result_ovr(X_train_v, X_test_v, y_train, y_test)\n",
    "results\n",
    "#### ... pasta 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 16 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Vetorização: CountVectorizer\n",
    "* Abordagem One vs Rest\n",
    "* Staking Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.655514</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.427880</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.355026</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.606378</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.050887</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.044889</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.163539</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>6.824861</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.328615</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.655514  0.666667\n",
       "1       AdaBoostClassifier:          0.427880  0.633333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.016952  0.500000\n",
       "5               GaussianNB:          0.017944  0.416667\n",
       "6              BernoulliNB:          0.014961  0.666667\n",
       "7            MultinomialNB:          0.008975  0.650000\n",
       "8   RandomForestClassifier:          0.355026  0.683333\n",
       "9     ExtraTreesClassifier:          0.606378  0.650000\n",
       "10      LogisticRegression:          0.050887  0.683333\n",
       "11                     svm:          0.044889  0.633333\n",
       "12                 svm_rbf:          0.163539  0.633333\n",
       "13              stacking_1:          0.000000  0.683333\n",
       "14              stacking_2:          0.000000  0.666667\n",
       "15              stacking_3:          0.000000  0.683333\n",
       "16     Stacking_scikit_ovr:          6.824861  0.700000\n",
       "17           XGBClassifier:          0.328615  0.600000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "list_corpus = DATASET[\"RELATOCLIENTE_CLEAN\"].tolist()\n",
    "list_labels = DATASET[\"PROBLEMA\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, train_size=0.80, \n",
    "                                                                                random_state=28)\n",
    "X_train_v, count_vectorizer = cv(X_train)\n",
    "X_test_v = count_vectorizer.transform(X_test)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result_ovr(X_train_v, X_test_v, y_train, y_test)\n",
    "results\n",
    "#### ... pasta 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 17 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "* gensim.corpora.Dictionary e bag of words;\n",
    "* técnica para topic modelling: Latent Dirichlet Allocation (LDA)\n",
    "* 30 tópicos \n",
    "* Usando somente as colunas dos 30 tópicos criados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.0\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.5\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.0\n",
      "Acurácia: 0.3333333333333333\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.16666666666666666\n",
      "Acurácia: 0.6666666666666666\n",
      "Acurácia: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "DATASET[\"RELATOCLIENTE_CLEAN_T\"] = list(sent_to_words(DATASET.RELATOCLIENTE_CLEAN.values.tolist()))\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(DATASET.RELATOCLIENTE_CLEAN_T.values.tolist())\n",
    "# Create Corpus\n",
    "texts = DATASET.RELATOCLIENTE_CLEAN_T.values.tolist()\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# number of topics\n",
    "num_topics = 30\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics,\n",
    "                                       workers=2)\n",
    "\n",
    "# DATASET with topics\n",
    "for a in range( num_topics ):\n",
    "    column = \"TP\" + str(a + 1)\n",
    "    DATASET[column] = \" \"\n",
    "\n",
    "for i in range(len(DATASET)):\n",
    "    top_topics = (\n",
    "        lda_model.get_document_topics(corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "    )\n",
    "    topic_vec = [top_topics[j][1] for j in range(num_topics)]\n",
    "    \n",
    "    for a in range(num_topics):\n",
    "        column = \"TP\" + str(a + 1)\n",
    "        DATASET[column].iloc[i] = topic_vec[a]\n",
    "\n",
    "column = []\n",
    "for a in range(num_topics):\n",
    "    column.append(\"TP\" + str(a + 1))\n",
    "\n",
    "X = np.array(DATASET[column])\n",
    "y = np.array(DATASET.PROBLEMA)        \n",
    "        \n",
    "kf = KFold(50, shuffle=True, random_state=42)\n",
    "\n",
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    \n",
    "    p_ac = metrics.accuracy_score(y_val,  y_pred)\n",
    "    print(\"Acurácia: \" + str(p_ac))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 18 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* técnica para topic modelling: Latent Dirichlet Allocation (LDA)\n",
    "* Usando \n",
    "    * 30 tópicos\n",
    "    * texto(TF-IDF) variando max_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features: 10 #Acurácia: 0.4500\n",
      "max_features: 20 #Acurácia: 0.4667\n",
      "max_features: 30 #Acurácia: 0.6167\n",
      "max_features: 40 #Acurácia: 0.6833\n",
      "max_features: 50 #Acurácia: 0.6333\n",
      "max_features: 60 #Acurácia: 0.6333\n",
      "max_features: 70 #Acurácia: 0.6333\n",
      "max_features: 80 #Acurácia: 0.6333\n",
      "max_features: 90 #Acurácia: 0.6167\n",
      "max_features: 100 #Acurácia: 0.6167\n",
      "max_features: 110 #Acurácia: 0.6333\n",
      "max_features: 120 #Acurácia: 0.6667\n",
      "max_features: 130 #Acurácia: 0.6667\n",
      "max_features: 140 #Acurácia: 0.6667\n",
      "max_features: 150 #Acurácia: 0.6500\n",
      "max_features: 160 #Acurácia: 0.6667\n",
      "max_features: 170 #Acurácia: 0.6833\n",
      "max_features: 180 #Acurácia: 0.6833\n",
      "max_features: 190 #Acurácia: 0.6833\n",
      "max_features: 200 #Acurácia: 0.6833\n",
      "max_features: 210 #Acurácia: 0.6833\n",
      "max_features: 220 #Acurácia: 0.6833\n",
      "max_features: 230 #Acurácia: 0.6667\n",
      "max_features: 240 #Acurácia: 0.6833\n",
      "max_features: 250 #Acurácia: 0.6833\n",
      "max_features: 260 #Acurácia: 0.6833\n",
      "max_features: 270 #Acurácia: 0.6667\n",
      "max_features: 280 #Acurácia: 0.6833\n",
      "max_features: 290 #Acurácia: 0.6667\n",
      "max_features: 300 #Acurácia: 0.6667\n",
      "max_features: 310 #Acurácia: 0.6667\n",
      "max_features: 320 #Acurácia: 0.6667\n",
      "max_features: 330 #Acurácia: 0.6667\n",
      "max_features: 340 #Acurácia: 0.6667\n",
      "max_features: 350 #Acurácia: 0.6667\n",
      "max_features: 360 #Acurácia: 0.6667\n",
      "max_features: 370 #Acurácia: 0.6500\n",
      "max_features: 380 #Acurácia: 0.6667\n",
      "max_features: 390 #Acurácia: 0.6500\n",
      "max_features: 400 #Acurácia: 0.6500\n",
      "max_features: 410 #Acurácia: 0.6500\n",
      "max_features: 420 #Acurácia: 0.6500\n",
      "max_features: 430 #Acurácia: 0.6500\n",
      "max_features: 440 #Acurácia: 0.6500\n",
      "max_features: 450 #Acurácia: 0.6500\n",
      "max_features: 460 #Acurácia: 0.6500\n",
      "max_features: 470 #Acurácia: 0.6500\n",
      "max_features: 480 #Acurácia: 0.6500\n",
      "max_features: 490 #Acurácia: 0.6500\n",
      "max_features: 500 #Acurácia: 0.6500\n",
      "max_features: 510 #Acurácia: 0.6500\n",
      "max_features: 520 #Acurácia: 0.6500\n",
      "max_features: 530 #Acurácia: 0.6500\n",
      "max_features: 540 #Acurácia: 0.6500\n",
      "max_features: 550 #Acurácia: 0.6500\n",
      "max_features: 560 #Acurácia: 0.6500\n",
      "max_features: 570 #Acurácia: 0.6500\n",
      "max_features: 580 #Acurácia: 0.6500\n",
      "max_features: 590 #Acurácia: 0.6500\n",
      "max_features: 600 #Acurácia: 0.6500\n",
      "max_features: 610 #Acurácia: 0.6500\n",
      "max_features: 620 #Acurácia: 0.6500\n",
      "max_features: 630 #Acurácia: 0.6500\n",
      "max_features: 640 #Acurácia: 0.6500\n",
      "max_features: 650 #Acurácia: 0.6500\n",
      "max_features: 660 #Acurácia: 0.6500\n",
      "max_features: 670 #Acurácia: 0.6500\n",
      "max_features: 680 #Acurácia: 0.6500\n",
      "max_features: 690 #Acurácia: 0.6500\n",
      "max_features: 700 #Acurácia: 0.6500\n",
      "max_features: 710 #Acurácia: 0.6500\n",
      "max_features: 720 #Acurácia: 0.6500\n",
      "max_features: 730 #Acurácia: 0.6500\n",
      "max_features: 740 #Acurácia: 0.6500\n",
      "max_features: 750 #Acurácia: 0.6500\n",
      "max_features: 760 #Acurácia: 0.6500\n",
      "max_features: 770 #Acurácia: 0.6500\n",
      "max_features: 780 #Acurácia: 0.6500\n",
      "max_features: 790 #Acurácia: 0.6500\n",
      "max_features: 800 #Acurácia: 0.6500\n",
      "max_features: 810 #Acurácia: 0.6500\n",
      "max_features: 820 #Acurácia: 0.6500\n",
      "max_features: 830 #Acurácia: 0.6500\n",
      "max_features: 840 #Acurácia: 0.6500\n",
      "max_features: 850 #Acurácia: 0.6500\n",
      "max_features: 860 #Acurácia: 0.6500\n",
      "max_features: 870 #Acurácia: 0.6500\n",
      "max_features: 880 #Acurácia: 0.6500\n",
      "max_features: 890 #Acurácia: 0.6500\n",
      "max_features: 900 #Acurácia: 0.6500\n",
      "max_features: 910 #Acurácia: 0.6500\n",
      "max_features: 920 #Acurácia: 0.6500\n",
      "max_features: 930 #Acurácia: 0.6500\n",
      "max_features: 940 #Acurácia: 0.6500\n",
      "max_features: 950 #Acurácia: 0.6500\n",
      "max_features: 960 #Acurácia: 0.6500\n",
      "max_features: 970 #Acurácia: 0.6500\n",
      "max_features: 980 #Acurácia: 0.6500\n",
      "max_features: 990 #Acurácia: 0.6500\n"
     ]
    }
   ],
   "source": [
    "for a in range(10, 1000 , 10):\n",
    "    vectorizer = TfidfVectorizer( max_features= a)\n",
    "    XX = vectorizer.fit_transform(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "    yy = DATASET[\"PROBLEMA\"]\n",
    "    XXX = hstack((XX, X.astype(float)))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split( XXX,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    Y_previsto_LR = lr.predict(X_test)\n",
    "\n",
    "    # Análise da previsão\n",
    "    p_ac = metrics.accuracy_score(y_test, np.floor( Y_previsto_LR) )\n",
    "    print(\"max_features: \"+ str(a) + \" \" + \"#Acurácia: {:.4f}\".format(p_ac) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 19 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* técnica para topic modelling: Latent Dirichlet Allocation (LDA)\n",
    "* Usando \n",
    "    * max_features  = 870\n",
    "    * Variando número de tópicos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_topics: 2 #Acurácia: 0.7000\n",
      "num_topics: 6 #Acurácia: 0.6333\n",
      "num_topics: 10 #Acurácia: 0.6167\n",
      "num_topics: 14 #Acurácia: 0.6000\n",
      "num_topics: 18 #Acurácia: 0.6500\n",
      "num_topics: 22 #Acurácia: 0.6333\n",
      "num_topics: 26 #Acurácia: 0.6667\n",
      "num_topics: 30 #Acurácia: 0.6333\n",
      "num_topics: 34 #Acurácia: 0.6500\n",
      "num_topics: 38 #Acurácia: 0.6167\n",
      "num_topics: 42 #Acurácia: 0.5833\n",
      "num_topics: 46 #Acurácia: 0.5833\n",
      "num_topics: 50 #Acurácia: 0.5833\n",
      "num_topics: 54 #Acurácia: 0.6167\n",
      "num_topics: 58 #Acurácia: 0.5667\n"
     ]
    }
   ],
   "source": [
    "for num_topics in range(2, 60 , 4):\n",
    "# number of topics\n",
    "#num_topics = 30\n",
    "\n",
    "# Build LDA model\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics,\n",
    "                                       workers=2)\n",
    "    rev_train = DATASET\n",
    "    lda_train = lda_model\n",
    "\n",
    "\n",
    "    for a in range( num_topics ):\n",
    "        column = \"TP\" + str(a + 1)\n",
    "        rev_train[column] = \" \"\n",
    "\n",
    "    for i in range(len(rev_train)):\n",
    "        top_topics = (\n",
    "            lda_train.get_document_topics(corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "        )\n",
    "        topic_vec = [top_topics[j][1] for j in range(num_topics)]\n",
    "    \n",
    "        for a in range(num_topics):\n",
    "            column = \"TP\" + str(a + 1)\n",
    "            rev_train[column].iloc[i] = topic_vec[a]\n",
    "         \n",
    "    column = []\n",
    "    for a in range(num_topics):\n",
    "        column.append(\"TP\" + str(a + 1))\n",
    "\n",
    "    X = np.array(rev_train[column])\n",
    "    y = np.array(rev_train.PROBLEMA)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer( max_features= 930)\n",
    "    XX = vectorizer.fit_transform(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "    yy = DATASET[\"PROBLEMA\"]\n",
    "    XXX = hstack((XX, X.astype(float)))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split( XXX,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    Y_previsto_LR = lr.predict(X_test)\n",
    "\n",
    "    # Análise da previsão\n",
    "    p_ac = metrics.accuracy_score(y_test, np.floor( Y_previsto_LR) )\n",
    "    print(\"num_topics: \"+ str(num_topics) + \" \" + \"#Acurácia: {:.4f}\".format(p_ac) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 20 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* gensim.similarities\t\n",
    "    * Word Embedding Similarity Index\n",
    "* Similaridade entre as string escolhidas para representar as classes de problemas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 796/796 [00:00<00:00, 4723.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.153721</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.071831</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.409910</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.410899</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.067814</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.121671</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit:</td>\n",
       "      <td>1.464122</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.268283</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OvR_RF:</td>\n",
       "      <td>0.350087</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.153721  0.650000\n",
       "1       AdaBoostClassifier:          0.071831  0.516667\n",
       "2     Voting_LR3_SVC1_ETC2:          0.409910  0.666667\n",
       "3     Voting_LR1_SVC1_ETC1:          0.410899  0.666667\n",
       "4   DecisionTreeClassifier:          0.002991  0.600000\n",
       "5               GaussianNB:          0.002965  0.516667\n",
       "6              BernoulliNB:          0.002998  0.616667\n",
       "7            MultinomialNB:          0.002989  0.633333\n",
       "8   RandomForestClassifier:          0.067814  0.600000\n",
       "9     ExtraTreesClassifier:          0.121671  0.650000\n",
       "10      LogisticRegression:          0.032917  0.683333\n",
       "11                     svm:          0.012960  0.650000\n",
       "12                 svm_rbf:          0.055851  0.650000\n",
       "13              stacking_1:          0.000000  0.683333\n",
       "14              stacking_2:          0.000000  0.650000\n",
       "15              stacking_3:          0.000000  0.666667\n",
       "16         Stacking_scikit:          1.464122  0.650000\n",
       "17           XGBClassifier:          0.268283  0.683333\n",
       "18                  OvR_RF:          0.350087  0.683333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "DATASET[\"RELATOCLIENTE_CLEAN_T\"] = list(sent_to_words(DATASET.RELATOCLIENTE_CLEAN.values.tolist()))\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(DATASET.RELATOCLIENTE_CLEAN_T.values.tolist())\n",
    "# Create Corpus\n",
    "texts = DATASET.RELATOCLIENTE_CLEAN_T.values.tolist()\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "dictionary = Dictionary(DATASET.RELATOCLIENTE_CLEAN_T.values.tolist() )\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "w2v_model = Word2Vec( DATASET.RELATOCLIENTE_CLEAN_T.values.tolist(), workers=2, min_count=5, seed=12345)\n",
    "similarity_index = WordEmbeddingSimilarityIndex(w2v_model.wv)\n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf, nonzero_limit=100)\n",
    "\n",
    "s_modem_sem_sincronismo = \"conexao internet massiva sincronismo modem status sucesso testes procedimento telefone\".lower().split()\n",
    "s_massiva = \"massiva rede interrupcao ntt aberto primaria prazo gpon rftth\".lower().split()\n",
    "s_modem_sincronizado_e_autenticado = \"conexao internet modem procedimento massiva sucesso sincronizado status acesso testes\".lower().split()\n",
    "s_parametros_ruins = \"status attenuation margin parametros noise ont indicator conexao velocidade ruins\".lower().split()\n",
    "s_baixa_velocidade = \"ping upload download velocidade teste lentidao testes baixa cabo reclama\".lower().split()\n",
    "s_queda_intermitencia = \"quedas status conexao reinit internet attenuation ont ngasp power procedimentos\".lower().split()\n",
    "\n",
    "s_modem_sem_sincronismo = id2word.doc2bow(s_modem_sem_sincronismo)\n",
    "s_massiva = id2word.doc2bow(s_massiva)\n",
    "s_modem_sincronizado_e_autenticado = id2word.doc2bow(s_modem_sincronizado_e_autenticado)\n",
    "s_parametros_ruins = id2word.doc2bow(s_parametros_ruins)\n",
    "s_baixa_velocidade = id2word.doc2bow(s_baixa_velocidade)\n",
    "s_queda_intermitencia = id2word.doc2bow(s_queda_intermitencia)\n",
    "\n",
    "s0 = s_modem_sem_sincronismo\n",
    "s1 = s_massiva\n",
    "s2 = s_modem_sincronizado_e_autenticado\n",
    "s3 = s_parametros_ruins\n",
    "s4 = s_baixa_velocidade\n",
    "s5 = s_queda_intermitencia\n",
    "\n",
    "ss = [s0, s1, s2, s3, s4, s5]\n",
    "\n",
    "DATASET[\"S0\"] = 0.0\n",
    "DATASET[\"S1\"] = 0.0\n",
    "DATASET[\"S2\"] = 0.0\n",
    "DATASET[\"S3\"] = 0.0\n",
    "DATASET[\"S4\"] = 0.0\n",
    "DATASET[\"S5\"] = 0.0\n",
    "\n",
    "for a in range(len(DATASET)):\n",
    "    doc_vec = DATASET.iloc(0)[a][3]\n",
    "    doc_bow = id2word.doc2bow( doc_vec)\n",
    "        \n",
    "    DATASET[\"S0\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s0, normalized=(True, True))\n",
    "    DATASET[\"S1\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s1, normalized=(True, True))\n",
    "    DATASET[\"S2\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s2, normalized=(True, True))\n",
    "    DATASET[\"S3\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s3, normalized=(True, True))\n",
    "    DATASET[\"S4\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s4, normalized=(True, True))\n",
    "    DATASET[\"S5\"].iloc[a] = similarity_matrix.inner_product( doc_bow , s5, normalized=(True, True))\n",
    "\n",
    "X = np.array(DATASET[[\"S0\", \"S1\", \"S2\", \"S3\", \"S4\", \"S5\" ]])\n",
    "y = np.array(DATASET.PROBLEMA)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X,\n",
    "                                                     y, \n",
    "                                                     train_size=0.80, random_state=28)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result(X_train_v, X_test_v, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 21 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* gensim.similarities\t\n",
    "    * Word Embedding Similarity Index\n",
    "* teste usando\n",
    "    * Colunas de similaridade\n",
    "    * Texto (TF-IDF) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features: 100 #Acurácia: 0.7000\n",
      "max_features: 150 #Acurácia: 0.7000\n",
      "max_features: 200 #Acurácia: 0.6667\n",
      "max_features: 250 #Acurácia: 0.7333\n",
      "max_features: 300 #Acurácia: 0.7167\n",
      "max_features: 350 #Acurácia: 0.7167\n",
      "max_features: 400 #Acurácia: 0.7333\n",
      "max_features: 450 #Acurácia: 0.7500\n",
      "max_features: 500 #Acurácia: 0.7333\n",
      "max_features: 550 #Acurácia: 0.7333\n",
      "max_features: 600 #Acurácia: 0.7333\n",
      "max_features: 650 #Acurácia: 0.7333\n",
      "max_features: 700 #Acurácia: 0.7333\n",
      "max_features: 750 #Acurácia: 0.7333\n",
      "max_features: 800 #Acurácia: 0.7333\n",
      "max_features: 850 #Acurácia: 0.7333\n",
      "max_features: 900 #Acurácia: 0.7333\n",
      "max_features: 950 #Acurácia: 0.7333\n",
      "max_features: 1000 #Acurácia: 0.7333\n",
      "max_features: 1050 #Acurácia: 0.7333\n",
      "max_features: 1100 #Acurácia: 0.7333\n",
      "max_features: 1150 #Acurácia: 0.7333\n",
      "max_features: 1200 #Acurácia: 0.7333\n",
      "max_features: 1250 #Acurácia: 0.7333\n",
      "max_features: 1300 #Acurácia: 0.7333\n",
      "max_features: 1350 #Acurácia: 0.7333\n",
      "max_features: 1400 #Acurácia: 0.7333\n",
      "max_features: 1450 #Acurácia: 0.7333\n",
      "max_features: 1500 #Acurácia: 0.7333\n",
      "max_features: 1550 #Acurácia: 0.7333\n",
      "max_features: 1600 #Acurácia: 0.7333\n",
      "max_features: 1650 #Acurácia: 0.7333\n",
      "max_features: 1700 #Acurácia: 0.7333\n",
      "max_features: 1750 #Acurácia: 0.7333\n",
      "max_features: 1800 #Acurácia: 0.7333\n",
      "max_features: 1850 #Acurácia: 0.7333\n",
      "max_features: 1900 #Acurácia: 0.7333\n",
      "max_features: 1950 #Acurácia: 0.7333\n"
     ]
    }
   ],
   "source": [
    "for a in range(100, 2000, 50):\n",
    "    vectorizer = TfidfVectorizer( max_features= a)\n",
    "    XX = vectorizer.fit_transform(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "    XXX = hstack((XX, X.astype(float)))\n",
    "    y = np.array(DATASET.PROBLEMA)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split( XXX,\n",
    "                                                     y, \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "    \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "    lr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    Y_previsto_LR = lr.predict(X_test)\n",
    "\n",
    "    # Análise da previsão\n",
    "    p_ac = metrics.accuracy_score(y_test, np.floor( Y_previsto_LR) )\n",
    "    print(\"max_features: \"+ str(a) + \" \" + \"#Acurácia: {:.4f}\".format(p_ac) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 22 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Passagem para forma numérica:\n",
    "    * gensim.corpora.Dictionary e bag of words;\n",
    "* gensim.similarities\t\n",
    "    * Word Embedding Similarity Index\n",
    "* teste usando\n",
    "    * 6 colunas de similaridade\n",
    "    * 6 tópicos ( topic modelling LDA )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.997371</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.360032</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.342084</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.505674</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>5.280928</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.183509</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.997371  0.533333\n",
       "1       AdaBoostClassifier:          0.360032  0.450000\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.010973  0.350000\n",
       "5               GaussianNB:          0.004984  0.350000\n",
       "6              BernoulliNB:          0.004987  0.083333\n",
       "7            MultinomialNB:          0.005961  0.233333\n",
       "8   RandomForestClassifier:          0.342084  0.416667\n",
       "9     ExtraTreesClassifier:          0.505674  0.416667\n",
       "10      LogisticRegression:          0.025930  0.400000\n",
       "11                     svm:          0.017246  0.483333\n",
       "12                 svm_rbf:          0.048869  0.483333\n",
       "13              stacking_1:          0.000000  0.533333\n",
       "14              stacking_2:          0.000000  0.333333\n",
       "15              stacking_3:          0.000000  0.500000\n",
       "16     Stacking_scikit_ovr:          5.280928  0.416667\n",
       "17           XGBClassifier:          0.183509  0.366667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = 6\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics= 6,\n",
    "                                       workers=2)\n",
    "\n",
    "rev_train = DATASET\n",
    "lda_train = lda_model\n",
    "\n",
    "for a in range( num_topics ):\n",
    "    column = \"TP\" + str(a + 1)\n",
    "    rev_train[column] = \" \"\n",
    "\n",
    "for i in range(len(rev_train)):\n",
    "    top_topics = (\n",
    "        lda_train.get_document_topics(corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "    )\n",
    "    topic_vec = [top_topics[j][1] for j in range(num_topics)]\n",
    "    \n",
    "    for a in range(num_topics):\n",
    "        column = \"TP\" + str(a + 1)\n",
    "        rev_train[column].iloc[i] = topic_vec[a]\n",
    "\n",
    "column = []\n",
    "for a in range(num_topics):\n",
    "    column.append(\"TP\" + str(a + 1))\n",
    "\n",
    "X_t = np.array(rev_train[column])\n",
    "y = np.array(rev_train.PROBLEMA)\n",
    "\n",
    "XXX = np.append(X_t.astype(float), X, axis=1).astype(float)\n",
    "y = np.array(DATASET.PROBLEMA)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( XXX,\n",
    "                                                     y, \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "results = get_tests_result_ovr(X_train, X_test, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 23 with the complete dataset\n",
    "* Sem remover palavras mais frequentes;\n",
    "* Removendo stopwords de forma personalizada;\n",
    "* 7000 registros para cada classe de problema;\n",
    "* Comparação\n",
    "    * CountVectorizer(nível word, char e ngrams)\n",
    "    * Tf-IDF (nível word, char e ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "DATASET[\"RELATOCLIENTE_CLEAN_T\"] = list(sent_to_words(DATASET.RELATOCLIENTE_CLEAN.values.tolist()))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( DATASET[\"RELATOCLIENTE_CLEAN\"] ,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "# CountVectorizer word level\n",
    "# X_train_count_vect_w, X_test_count_vect_w, y_train, y_test\n",
    "count_vect_w = CountVectorizer(analyzer='word')\n",
    "count_vect_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_w =  count_vect_w.transform(X_train)\n",
    "X_test_count_vect_w =  count_vect_w.transform(X_test)\n",
    "\n",
    "# CountVectorizer word ngram level\n",
    "# X_train_count_vect_w_ngram, X_test_count_vect_w_ngram, y_train, y_test\n",
    "count_vect_w_ngram = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "count_vect_w_ngram.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_w_ngram =  count_vect_w_ngram.transform(X_train)\n",
    "X_test_count_vect_w_ngram =  count_vect_w_ngram.transform(X_test)\n",
    "\n",
    "# CountVectorizer char level\n",
    "# X_train_count_vect_char, X_test_count_vect_char, y_train, y_test\n",
    "count_vect_char = CountVectorizer(analyzer='char', max_features=5000)\n",
    "count_vect_char.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_char =  count_vect_char.transform(X_train)\n",
    "X_test_count_vect_char =  count_vect_char.transform(X_test)\n",
    "\n",
    "# CountVectorizer char ngram level\n",
    "# X_train_count_vect_char_ngram, X_test_count_vect_char_ngram, y_train, y_test\n",
    "count_vect_char_ngram = CountVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "count_vect_char_ngram.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_char_ngram =  count_vect_char_ngram.transform(X_train)\n",
    "X_test_count_vect_char_ngram =  count_vect_char_ngram.transform(X_test)\n",
    "\n",
    "#########################################\n",
    "\n",
    "# tf-idf word level\n",
    "# X_train_tfidf_w, X_test_tfidf_w, y_train, y_test\n",
    "tfidf_w = TfidfVectorizer(analyzer='word', max_features=500)\n",
    "tfidf_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_w =  tfidf_w.transform(X_train)\n",
    "X_test_tfidf_w =  tfidf_w.transform(X_test)\n",
    "\n",
    "# tf-idf word ngram level  \n",
    "# X_train_tfidf_w_ngram, X_test_tfidf_w_ngram, y_train, y_test\n",
    "tfidf_w_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_w_ngram.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_w_ngram =  tfidf_w_ngram.transform(X_train)\n",
    "X_test_tfidf_w_ngram =  tfidf_w_ngram.transform(X_test)\n",
    "\n",
    "# tf-idf char level \n",
    "# X_train_tfidf_char, X_test_tfidf_char, y_train, y_test\n",
    "tfidf_char = TfidfVectorizer(analyzer='char', max_features=5000)\n",
    "tfidf_char.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_char =  tfidf_char.transform(X_train) \n",
    "X_test_tfidf_char =  tfidf_char.transform(X_test)\n",
    "\n",
    "# tf-idf char ngram level\n",
    "# X_train_tfidf_char_ngram, X_test_tfidf_char_ngram, y_train, y_test\n",
    "tfidf_char_ngram = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_char_ngram.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_char_ngram =  tfidf_char_ngram.transform(X_train) \n",
    "X_test_tfidf_char_ngram =  tfidf_char_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-1 CountVectorizer word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.734650</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.462766</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.016954</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.389980</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.763045</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.044881</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.163567</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>7.108071</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.313157</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.734650  0.666667\n",
       "1       AdaBoostClassifier:          0.462766  0.616667\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.016951  0.466667\n",
       "5               GaussianNB:          0.018931  0.416667\n",
       "6              BernoulliNB:          0.016954  0.650000\n",
       "7            MultinomialNB:          0.009973  0.650000\n",
       "8   RandomForestClassifier:          0.389980  0.650000\n",
       "9     ExtraTreesClassifier:          0.763045  0.650000\n",
       "10      LogisticRegression:          0.049867  0.683333\n",
       "11                     svm:          0.044881  0.616667\n",
       "12                 svm_rbf:          0.163567  0.616667\n",
       "13              stacking_1:          0.000000  0.666667\n",
       "14              stacking_2:          0.000000  0.683333\n",
       "15              stacking_3:          0.000000  0.683333\n",
       "16     Stacking_scikit_ovr:          7.108071  0.683333\n",
       "17           XGBClassifier:          0.313157  0.600000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_count_vect_w, X_test_count_vect_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-2 CountVectorizer word ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>2.768041</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.938482</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.071809</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.120684</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.078788</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.040861</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.554540</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>1.331443</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.070904</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.266310</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>10.603854</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.460743</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          2.768041  0.566667\n",
       "1       AdaBoostClassifier:          0.938482  0.583333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.071809  0.616667\n",
       "5               GaussianNB:          0.120684  0.483333\n",
       "6              BernoulliNB:          0.078788  0.366667\n",
       "7            MultinomialNB:          0.040861  0.600000\n",
       "8   RandomForestClassifier:          0.554540  0.483333\n",
       "9     ExtraTreesClassifier:          1.331443  0.483333\n",
       "10      LogisticRegression:          0.074800  0.650000\n",
       "11                     svm:          0.070904  0.583333\n",
       "12                 svm_rbf:          0.266310  0.583333\n",
       "13              stacking_1:          0.000000  0.616667\n",
       "14              stacking_2:          0.000000  0.533333\n",
       "15              stacking_3:          0.000000  0.583333\n",
       "16     Stacking_scikit_ovr:         10.603854  0.583333\n",
       "17           XGBClassifier:          0.460743  0.500000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_count_vect_w_ngram, X_test_count_vect_w_ngram, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-3 CountVectorizer char level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>1.082810</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.424859</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.369018</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.640395</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.141597</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.084804</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>6.710041</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.217395</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          1.082810  0.550000\n",
       "1       AdaBoostClassifier:          0.424859  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.013963  0.400000\n",
       "5               GaussianNB:          0.004986  0.283333\n",
       "6              BernoulliNB:          0.006981  0.316667\n",
       "7            MultinomialNB:          0.004987  0.600000\n",
       "8   RandomForestClassifier:          0.369018  0.566667\n",
       "9     ExtraTreesClassifier:          0.640395  0.516667\n",
       "10      LogisticRegression:          0.141597  0.550000\n",
       "11                     svm:          0.026928  0.500000\n",
       "12                 svm_rbf:          0.084804  0.500000\n",
       "13              stacking_1:          0.000000  0.550000\n",
       "14              stacking_2:          0.000000  0.500000\n",
       "15              stacking_3:          0.000000  0.550000\n",
       "16     Stacking_scikit_ovr:          6.710041  0.483333\n",
       "17           XGBClassifier:          0.217395  0.500000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_count_vect_char, X_test_count_vect_char, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-4 CountVectorizer char ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>2.444531</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.769940</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.059846</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.050868</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.044874</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.404911</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.765019</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.197469</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.257311</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>1.077118</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>8.819555</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.424838</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          2.444531  0.683333\n",
       "1       AdaBoostClassifier:          0.769940  0.666667\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.059846  0.550000\n",
       "5               GaussianNB:          0.050868  0.283333\n",
       "6              BernoulliNB:          0.044874  0.666667\n",
       "7            MultinomialNB:          0.015957  0.700000\n",
       "8   RandomForestClassifier:          0.404911  0.666667\n",
       "9     ExtraTreesClassifier:          0.765019  0.683333\n",
       "10      LogisticRegression:          0.197469  0.733333\n",
       "11                     svm:          0.257311  0.716667\n",
       "12                 svm_rbf:          1.077118  0.716667\n",
       "13              stacking_1:          0.000000  0.683333\n",
       "14              stacking_2:          0.000000  0.716667\n",
       "15              stacking_3:          0.000000  0.683333\n",
       "16     Stacking_scikit_ovr:          8.819555  0.716667\n",
       "17           XGBClassifier:          0.424838  0.700000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_count_vect_char_ngram, X_test_count_vect_char_ngram, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-5 tf-idf word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>0.497153</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.473733</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.018979</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.377984</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.660234</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>6.535633</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.306157</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          0.497153  0.616667\n",
       "1       AdaBoostClassifier:          0.473733  0.583333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.018979  0.516667\n",
       "5               GaussianNB:          0.009973  0.383333\n",
       "6              BernoulliNB:          0.009972  0.666667\n",
       "7            MultinomialNB:          0.005984  0.616667\n",
       "8   RandomForestClassifier:          0.377984  0.666667\n",
       "9     ExtraTreesClassifier:          0.660234  0.600000\n",
       "10      LogisticRegression:          0.032911  0.700000\n",
       "11                     svm:          0.046875  0.666667\n",
       "12                 svm_rbf:          0.178527  0.666667\n",
       "13              stacking_1:          0.000000  0.650000\n",
       "14              stacking_2:          0.000000  0.666667\n",
       "15              stacking_3:          0.000000  0.633333\n",
       "16     Stacking_scikit_ovr:          6.535633  0.616667\n",
       "17           XGBClassifier:          0.306157  0.616667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_tfidf_w, X_test_tfidf_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-6 tf-idf word ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>3.901750</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.963418</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.076771</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.067820</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.022921</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.544514</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>1.407300</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.058843</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.071779</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.271335</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>10.766382</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.493679</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          3.901750  0.466667\n",
       "1       AdaBoostClassifier:          0.963418  0.566667\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.076771  0.533333\n",
       "5               GaussianNB:          0.115714  0.483333\n",
       "6              BernoulliNB:          0.067820  0.366667\n",
       "7            MultinomialNB:          0.022921  0.583333\n",
       "8   RandomForestClassifier:          0.544514  0.433333\n",
       "9     ExtraTreesClassifier:          1.407300  0.500000\n",
       "10      LogisticRegression:          0.058843  0.616667\n",
       "11                     svm:          0.071779  0.633333\n",
       "12                 svm_rbf:          0.271335  0.633333\n",
       "13              stacking_1:          0.000000  0.616667\n",
       "14              stacking_2:          0.000000  0.516667\n",
       "15              stacking_3:          0.000000  0.483333\n",
       "16     Stacking_scikit_ovr:         10.766382  0.583333\n",
       "17           XGBClassifier:          0.493679  0.583333"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_tfidf_w_ngram, X_test_tfidf_w_ngram, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-7 tf-idf char level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>1.126647</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>0.488715</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.018961</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.393940</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.646276</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>0.078818</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>6.226883</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.222374</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          1.126647  0.516667\n",
       "1       AdaBoostClassifier:          0.488715  0.533333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.018961  0.300000\n",
       "5               GaussianNB:          0.005981  0.333333\n",
       "6              BernoulliNB:          0.006951  0.316667\n",
       "7            MultinomialNB:          0.005014  0.300000\n",
       "8   RandomForestClassifier:          0.393940  0.483333\n",
       "9     ExtraTreesClassifier:          0.646276  0.533333\n",
       "10      LogisticRegression:          0.033877  0.416667\n",
       "11                     svm:          0.025932  0.566667\n",
       "12                 svm_rbf:          0.078818  0.566667\n",
       "13              stacking_1:          0.000000  0.583333\n",
       "14              stacking_2:          0.000000  0.466667\n",
       "15              stacking_3:          0.000000  0.566667\n",
       "16     Stacking_scikit_ovr:          6.226883  0.550000\n",
       "17           XGBClassifier:          0.222374  0.533333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_tfidf_char, X_test_tfidf_char, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23-8 tf-idf char ngram level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier:</td>\n",
       "      <td>2.193224</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier:</td>\n",
       "      <td>1.234671</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting_LR3_SVC1_ETC2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting_LR1_SVC1_ETC1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier:</td>\n",
       "      <td>0.103723</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB:</td>\n",
       "      <td>0.038895</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB:</td>\n",
       "      <td>0.037901</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB:</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.435835</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.776924</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.053847</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.338104</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm_rbf:</td>\n",
       "      <td>1.440136</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stacking_2:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stacking_3:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>8.591094</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.496649</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0            MLPClassifier:          2.193224  0.700000\n",
       "1       AdaBoostClassifier:          1.234671  0.633333\n",
       "2     Voting_LR3_SVC1_ETC2:          0.000000  0.000000\n",
       "3     Voting_LR1_SVC1_ETC1:          0.000000  0.000000\n",
       "4   DecisionTreeClassifier:          0.103723  0.616667\n",
       "5               GaussianNB:          0.038895  0.283333\n",
       "6              BernoulliNB:          0.037901  0.666667\n",
       "7            MultinomialNB:          0.010967  0.650000\n",
       "8   RandomForestClassifier:          0.435835  0.683333\n",
       "9     ExtraTreesClassifier:          0.776924  0.683333\n",
       "10      LogisticRegression:          0.053847  0.700000\n",
       "11                     svm:          0.338104  0.716667\n",
       "12                 svm_rbf:          1.440136  0.716667\n",
       "13              stacking_1:          0.000000  0.716667\n",
       "14              stacking_2:          0.000000  0.683333\n",
       "15              stacking_3:          0.000000  0.683333\n",
       "16     Stacking_scikit_ovr:          8.591094  0.716667\n",
       "17           XGBClassifier:          0.496649  0.683333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr(X_train_tfidf_char_ngram, X_test_tfidf_char_ngram, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 24 with the complete dataset \n",
    "* Other kind of problem (Motivo 3)\n",
    "* Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( DATASET[\"RELATOCLIENTE_CLEAN\"] ,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "# CountVectorizer word level\n",
    "# X_train_count_vect_w, X_test_count_vect_w, y_train, y_test\n",
    "count_vect_w = CountVectorizer(analyzer='word')\n",
    "count_vect_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"].astype('U').values)\n",
    "X_train_count_vect_w =  count_vect_w.transform(X_train.astype('U').values)\n",
    "X_test_count_vect_w =  count_vect_w.transform(X_test.astype('U').values)\n",
    "\n",
    "# tf-idf word level\n",
    "# X_train_tfidf_w, X_test_tfidf_w, y_train, y_test\n",
    "tfidf_w = TfidfVectorizer(analyzer='word')\n",
    "tfidf_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"].astype('U').values)\n",
    "X_train_tfidf_w =  tfidf_w.transform(X_train.astype('U').values)\n",
    "X_test_tfidf_w =  tfidf_w.transform(X_test.astype('U').values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Queda / Intermitência               50\n",
       "Modem sem sincronismo               50\n",
       "Massiva                             50\n",
       "Modem sincronizado e autenticado    50\n",
       "Parâmetros Ruins                    50\n",
       "Baixa Velocidade                    50\n",
       "Name: PROBLEMA, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET[\"PROBLEMA\"].value_counts()[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24 Count vectorizer word level\n",
    "* MemoryError: Unable to allocate 34.7 GiB for an array with shape (124080, 37545) and data type int64\n",
    "* GaussianNB removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests_result_ovr_26(X_train_v, X_test_v, y_train, y_test):\n",
    "    all_res = []\n",
    "    \n",
    "    ### RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1, n_jobs=5)\n",
    "    train_test_time, accuracy, Y_previsto_RF = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"RandomForestClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"RandomForestClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### ExtraTreesClassifier\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=0, n_jobs=5 )\n",
    "    train_test_time, accuracy, Y_previsto_ERT = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"ExtraTreesClassifier: \" + str( accuracy) ) \n",
    "    all_res.append([\"ExtraTreesClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0, n_jobs=5)\n",
    "    train_test_time, accuracy, Y_previsto_LR = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"LogisticRegression: \" + str( accuracy) ) \n",
    "    all_res.append([\"LogisticRegression: \", train_test_time, accuracy])\n",
    "    \n",
    "    ### svm\n",
    "    clf = svm.SVC()\n",
    "    train_test_time, accuracy, Y_previsto_SVM = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "    #print( \"svm: \" + str( accuracy) ) \n",
    "    all_res.append([\"svm: \", train_test_time, accuracy])\n",
    "        \n",
    "    ### Stacking 1\n",
    "    stack_result = []\n",
    "    for a in range(len(Y_previsto_RF)):\n",
    "        elements = []\n",
    "        elements.append( np.floor( Y_previsto_RF[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_ERT[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_LR[a] ) )\n",
    "        elements.append( np.floor( Y_previsto_SVM[a] ) )\n",
    "        #elements.append( np.floor( Y_previsto_svc[a] ) )\n",
    "        stack_result.append( stats.mode(elements).mode[0])\n",
    "        \n",
    "    accuracy = metrics.accuracy_score(y_test,  np.array(stack_result, dtype=\"int64\" )  )\n",
    "    all_res.append([\"stacking_1: \", 0 , accuracy])\n",
    "       \n",
    "    ### Stacking_scikit\n",
    "    clf1 = RandomForestClassifier(n_estimators=50, random_state=1, n_jobs=5)\n",
    "    clf2 = LogisticRegression(random_state=0, n_jobs=5)\n",
    "    clf3 = SVC()\n",
    "    clf4 = ExtraTreesClassifier(n_estimators=100, random_state=0, n_jobs=5)\n",
    "    estimators = [('rf', clf1), ('lr', clf2), ('svc', clf3), ('etc', clf4)]\n",
    "    ini = time.time()\n",
    "    clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression(), n_jobs=5)\n",
    "    \n",
    "    ovr = OneVsRestClassifier(clf)\n",
    "    ovr.fit(X_train_v, y_train)\n",
    "    Y_Previsto_stacking = ovr.predict(X_test_v)\n",
    "    \n",
    "    fim = time.time()\n",
    "    train_test_time = fim-ini\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_Previsto_stacking)\n",
    "    all_res.append([\"Stacking_scikit_ovr: \", train_test_time , accuracy])\n",
    "    \n",
    "    ### XGBClassifier\n",
    "    Y_previsto_xgbc = 1\n",
    "    try:\n",
    "        clf = XGBClassifier(eval_metric='mlogloss')\n",
    "        train_test_time, accuracy, Y_previsto_xgbc = train_model_ovr(clf, X_train_v.tocsc(), X_test_v.tocsc(), y_train, y_test)\n",
    "        #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "        all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    except:\n",
    "        clf = XGBClassifier(eval_metric='mlogloss')\n",
    "        train_test_time, accuracy, Y_previsto_xgbc = train_model_ovr(clf, X_train_v, X_test_v, y_train, y_test)\n",
    "        #print( \"XGBClassifier: \" + str( accuracy) ) \n",
    "        all_res.append([\"XGBClassifier: \", train_test_time, accuracy])\n",
    "    \n",
    "    return pd.DataFrame( all_res, columns=[\"ALGORITHM\",\"TRAIN_TEST_TIME\", \"ACCURACY\"]  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24-1 Count vectorizer word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>1.475053</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.548533</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.045879</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>3.465724</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.315156</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0  RandomForestClassifier:          1.475053  0.650000\n",
       "1    ExtraTreesClassifier:          0.548533  0.650000\n",
       "2      LogisticRegression:          0.065853  0.683333\n",
       "3                     svm:          0.045879  0.616667\n",
       "4              stacking_1:          0.000000  0.666667\n",
       "5     Stacking_scikit_ovr:          3.465724  0.683333\n",
       "6           XGBClassifier:          0.315156  0.600000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr_26(X_train_count_vect_w, X_test_count_vect_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24-2 TF-IDF word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.296207</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.550527</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.048868</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.052889</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>3.452828</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.302168</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0  RandomForestClassifier:          0.296207  0.650000\n",
       "1    ExtraTreesClassifier:          0.550527  0.650000\n",
       "2      LogisticRegression:          0.048868  0.700000\n",
       "3                     svm:          0.052889  0.683333\n",
       "4              stacking_1:          0.000000  0.683333\n",
       "5     Stacking_scikit_ovr:          3.452828  0.650000\n",
       "6           XGBClassifier:          0.302168  0.683333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr_26(X_train_tfidf_w, X_test_tfidf_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 25 with the complete dataset\n",
    "* Other kind of problem (Motivo 3)\n",
    "* Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/PMON2021-NLP/\"\n",
    "file = \"DATASET_CLEAN.csv\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET = pd.read_csv(path + file, error_bad_lines=False, delimiter=';')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( DATASET[\"RELATOCLIENTE_CLEAN\"] ,\n",
    "                                                    DATASET[\"PROBLEMA\"], \n",
    "                                                    train_size=0.80, random_state=28)\n",
    "\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "# CountVectorizer word level\n",
    "# X_train_count_vect_w, X_test_count_vect_w, y_train, y_test\n",
    "count_vect_w = CountVectorizer(analyzer='word')\n",
    "count_vect_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_count_vect_w =  count_vect_w.transform(X_train)\n",
    "X_test_count_vect_w =  count_vect_w.transform(X_test)\n",
    "\n",
    "# tf-idf word level\n",
    "# X_train_tfidf_w, X_test_tfidf_w, y_train, y_test\n",
    "tfidf_w = TfidfVectorizer(analyzer='word')\n",
    "tfidf_w.fit(DATASET[\"RELATOCLIENTE_CLEAN\"])\n",
    "X_train_tfidf_w =  tfidf_w.transform(X_train)\n",
    "X_test_tfidf_w =  tfidf_w.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Queda / Intermitência               50\n",
       "Modem sem sincronismo               50\n",
       "Massiva                             50\n",
       "Modem sincronizado e autenticado    50\n",
       "Parâmetros Ruins                    50\n",
       "Baixa Velocidade                    50\n",
       "Name: PROBLEMA, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET[\"PROBLEMA\"].value_counts()[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25-1 Count vectorizer word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.285218</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.541559</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.061835</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>3.426970</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.311167</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0  RandomForestClassifier:          0.285218  0.650000\n",
       "1    ExtraTreesClassifier:          0.541559  0.650000\n",
       "2      LogisticRegression:          0.061835  0.683333\n",
       "3                     svm:          0.045900  0.616667\n",
       "4              stacking_1:          0.000000  0.666667\n",
       "5     Stacking_scikit_ovr:          3.426970  0.683333\n",
       "6           XGBClassifier:          0.311167  0.600000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr_26(X_train_count_vect_w, X_test_count_vect_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25-2 TF-IDF word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th>TRAIN_TEST_TIME</th>\n",
       "      <th>ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier:</td>\n",
       "      <td>0.296208</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier:</td>\n",
       "      <td>0.541557</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression:</td>\n",
       "      <td>0.044908</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm:</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stacking_1:</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stacking_scikit_ovr:</td>\n",
       "      <td>3.454113</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier:</td>\n",
       "      <td>0.304186</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ALGORITHM  TRAIN_TEST_TIME  ACCURACY\n",
       "0  RandomForestClassifier:          0.296208  0.650000\n",
       "1    ExtraTreesClassifier:          0.541557  0.650000\n",
       "2      LogisticRegression:          0.044908  0.700000\n",
       "3                     svm:          0.051861  0.683333\n",
       "4              stacking_1:          0.000000  0.683333\n",
       "5     Stacking_scikit_ovr:          3.454113  0.650000\n",
       "6           XGBClassifier:          0.304186  0.683333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_tests_result_ovr_26(X_train_tfidf_w, X_test_tfidf_w, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
